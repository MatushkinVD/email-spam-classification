{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84589940-e12f-4164-a9a6-76f06c76d5e5",
   "metadata": {},
   "source": [
    "# Классификация спама в электронной почте\n",
    "Ссылка: https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv.\n",
    "\n",
    "## Используемые инструменты\n",
    "Библиотеки:\n",
    " - pandas (Version: 2.3.1).\n",
    " - matplotlib (Version: 3.10.5).\n",
    " - time (модуль из стандартной библиотеки).\n",
    " - random (модуль из стандартной библиотеки).\n",
    " - warnings (модуль из стандартной библиотеки).\n",
    " - gc (модуль из стандартной библиотеки).\n",
    " - pympler (Version: 1.1).\n",
    " - scikit-learn (Version: 1.8.0).\n",
    " - catboost (Version: 1.2.8).\n",
    "\n",
    "Таблица:\n",
    " - emails.csv.\n",
    "\n",
    "## Содержание таблицы\n",
    "В таблице 3002 столбца. В первом столбце указано имя отправителя. Чтобы защитить конфиденциальность, вместо имён получателей указаны номера. В последнем столбце указаны метки для прогнозирования: 1 - спам, 0 - не спам. Остальные 3000 столбцов содержат 3000 наиболее часто встречающихся слов во всех электронных письмах после исключения неалфавитных символов/слов. В каждой строке указано количество вхождений каждого слова (столбца) в этом электронном письме (строке). Таким образом, информация обо всех 5172 электронных письмах хранится в компактном датафрейме, а не в отдельных текстовых файлах.\n",
    "\n",
    "## Подготовка и анализ данных\n",
    "### Загрузка всех инструментов\n",
    "Загрузка всех библиотек и функций/классов, используемых в работе. Для проверки качества моделей будут использоваться следующие метрики: матрица ошибок, LogLoss, ROC-AUC, PR-AUC. Задание \"random_seed\" для воспроизводства результатов. Игнорирование предупреждений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da68197a-cf4c-40e7-88b6-2d6f5cac9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "from pympler import asizeof\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import (confusion_matrix, log_loss, classification_report, roc_auc_score, roc_curve, RocCurveDisplay,\n",
    "                             precision_recall_curve, PrecisionRecallDisplay, average_precision_score)\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier,\n",
    "                              GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier)\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from catboost.utils import get_confusion_matrix\n",
    "\n",
    "random_seed = 1\n",
    "random.seed(a = random_seed)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20650810-ee06-4fca-b089-d3ee5937cfd2",
   "metadata": {},
   "source": [
    "Загрузка таблицы и просмотр первых и последних 5-ти строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57807ab3-93f1-40e2-9e6a-43694e11d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>Email 5168</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Email 5169</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>Email 5170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Email 5171</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>Email 5172</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  \\\n",
       "0        Email 1    0   0    1    0    0   0    2    0    0  ...         0   \n",
       "1        Email 2    8  13   24    6    6   2  102    1   27  ...         0   \n",
       "2        Email 3    0   0    1    0    0   0    8    0    0  ...         0   \n",
       "3        Email 4    0   5   22    0    5   1   51    2   10  ...         0   \n",
       "4        Email 5    7   6   17    1    5   2   57    0    9  ...         0   \n",
       "...          ...  ...  ..  ...  ...  ...  ..  ...  ...  ...  ...       ...   \n",
       "5167  Email 5168    2   2    2    3    0   0   32    0    0  ...         0   \n",
       "5168  Email 5169   35  27   11    2    6   5  151    4    3  ...         0   \n",
       "5169  Email 5170    0   0    1    1    0   0   11    0    0  ...         0   \n",
       "5170  Email 5171    2   7    1    0    2   1   28    2    0  ...         0   \n",
       "5171  Email 5172   22  24    5    1    6   5  148    8    2  ...         0   \n",
       "\n",
       "      jay  valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
       "0       0       0    0               0         0         0   0    0   \n",
       "1       0       0    0               0         0         0   1    0   \n",
       "2       0       0    0               0         0         0   0    0   \n",
       "3       0       0    0               0         0         0   0    0   \n",
       "4       0       0    0               0         0         0   1    0   \n",
       "...   ...     ...  ...             ...       ...       ...  ..  ...   \n",
       "5167    0       0    0               0         0         0   0    0   \n",
       "5168    0       0    0               0         0         0   1    0   \n",
       "5169    0       0    0               0         0         0   0    0   \n",
       "5170    0       0    0               0         0         0   1    0   \n",
       "5171    0       0    0               0         0         0   0    0   \n",
       "\n",
       "      Prediction  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "5167           0  \n",
       "5168           0  \n",
       "5169           1  \n",
       "5170           1  \n",
       "5171           0  \n",
       "\n",
       "[5172 rows x 3002 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv('emails.csv')\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60ff98d-6366-429d-8549-96a4587097b0",
   "metadata": {},
   "source": [
    "### Первичный анализ таблицы\n",
    "Статистическое описание колонки с именами почтовых отправителей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30005224-5651-4b5f-8a64-7042fcab05e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Email 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Email No.\n",
       "count       5172\n",
       "unique      5172\n",
       "top      Email 1\n",
       "freq           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe63d6-3d3d-403c-a230-6509682f4717",
   "metadata": {},
   "source": [
    "Каждому письму соответствует уникальный отправитель. Колонка важной информации для классификации спама не несёт и её можно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1500c0cf-9ae0-4403-91f2-8f45d832a63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
       "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
       "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
       "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
       "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
       "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
       "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
       "5167    2   2    2    3    0   0   32    0    0   5  ...         0    0   \n",
       "5168   35  27   11    2    6   5  151    4    3  23  ...         0    0   \n",
       "5169    0   0    1    1    0   0   11    0    0   1  ...         0    0   \n",
       "5170    2   7    1    0    2   1   28    2    0   8  ...         0    0   \n",
       "5171   22  24    5    1    6   5  148    8    2  23  ...         0    0   \n",
       "\n",
       "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0          0    0               0         0         0   0    0           0  \n",
       "1          0    0               0         0         0   1    0           0  \n",
       "2          0    0               0         0         0   0    0           0  \n",
       "3          0    0               0         0         0   0    0           0  \n",
       "4          0    0               0         0         0   1    0           0  \n",
       "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
       "5167       0    0               0         0         0   0    0           0  \n",
       "5168       0    0               0         0         0   1    0           0  \n",
       "5169       0    0               0         0         0   0    0           1  \n",
       "5170       0    0               0         0         0   1    0           1  \n",
       "5171       0    0               0         0         0   0    0           0  \n",
       "\n",
       "[5172 rows x 3001 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = emails.drop(columns = ['Email No.'])\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b83b2-4a92-44c0-abe1-d3d9bdf02585",
   "metadata": {},
   "source": [
    "Явное определение имени таргета для последующих расчётов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ff519c-3811-4199-bd3f-bf719bca74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Prediction'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d5e27-ce1d-4e65-b4ba-86b324a366ed",
   "metadata": {},
   "source": [
    "Проверка на наличие колонок с пропусками и вывод таких колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50f648fd-3dbc-476d-b2f5-4ceab9d854c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n"
     ]
    }
   ],
   "source": [
    "for column in emails.columns:\n",
    "    if emails[column].isna().any():\n",
    "        print(column)\n",
    "print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b411cf-bc10-4cfc-a2b7-3d299af4a4ba",
   "metadata": {},
   "source": [
    "Как видно - пропущенных значений вообще нет.\n",
    "\n",
    "Каждый признак - количество вхождений данного слова в текст письма. Поскольку письма бывают разной длины - большую информацию будет нести не количество слов, а их частота относительно других слов. Таким образом, следует преобразовать все значения в таблице как отношения количеств вхождений слов к общей сумме всех слов в письме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e758c0b-e3d6-47f2-a660-3061e1b1960c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.021590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.050049</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.015814</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.053023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.051378</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.054472</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the        to       ect       and       for        of         a  \\\n",
       "0     0.000000  0.000000  0.018868  0.000000  0.000000  0.000000  0.037736   \n",
       "1     0.003631  0.005901  0.010894  0.002724  0.002724  0.000908  0.046300   \n",
       "2     0.000000  0.000000  0.008850  0.000000  0.000000  0.000000  0.070796   \n",
       "3     0.000000  0.004907  0.021590  0.000000  0.004907  0.000981  0.050049   \n",
       "4     0.006512  0.005581  0.015814  0.000930  0.004651  0.001860  0.053023   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5167  0.003960  0.003960  0.003960  0.005941  0.000000  0.000000  0.063366   \n",
       "5168  0.011909  0.009187  0.003743  0.000681  0.002042  0.001701  0.051378   \n",
       "5169  0.000000  0.000000  0.005587  0.005587  0.000000  0.000000  0.061453   \n",
       "5170  0.002538  0.008883  0.001269  0.000000  0.002538  0.001269  0.035533   \n",
       "5171  0.008097  0.008833  0.001840  0.000368  0.002208  0.001840  0.054472   \n",
       "\n",
       "           you       hou        in  ...  connevey  jay  valued  lay  \\\n",
       "0     0.000000  0.000000  0.000000  ...       0.0  0.0     0.0  0.0   \n",
       "1     0.000454  0.012256  0.008171  ...       0.0  0.0     0.0  0.0   \n",
       "2     0.000000  0.000000  0.035398  ...       0.0  0.0     0.0  0.0   \n",
       "3     0.001963  0.009814  0.000981  ...       0.0  0.0     0.0  0.0   \n",
       "4     0.000000  0.008372  0.002791  ...       0.0  0.0     0.0  0.0   \n",
       "...        ...       ...       ...  ...       ...  ...     ...  ...   \n",
       "5167  0.000000  0.000000  0.009901  ...       0.0  0.0     0.0  0.0   \n",
       "5168  0.001361  0.001021  0.007826  ...       0.0  0.0     0.0  0.0   \n",
       "5169  0.000000  0.000000  0.005587  ...       0.0  0.0     0.0  0.0   \n",
       "5170  0.002538  0.000000  0.010152  ...       0.0  0.0     0.0  0.0   \n",
       "5171  0.002944  0.000736  0.008465  ...       0.0  0.0     0.0  0.0   \n",
       "\n",
       "      infrastructure  military  allowing        ff  dry  Prediction  \n",
       "0                0.0       0.0       0.0  0.000000  0.0           0  \n",
       "1                0.0       0.0       0.0  0.000454  0.0           0  \n",
       "2                0.0       0.0       0.0  0.000000  0.0           0  \n",
       "3                0.0       0.0       0.0  0.000000  0.0           0  \n",
       "4                0.0       0.0       0.0  0.000930  0.0           0  \n",
       "...              ...       ...       ...       ...  ...         ...  \n",
       "5167             0.0       0.0       0.0  0.000000  0.0           0  \n",
       "5168             0.0       0.0       0.0  0.000340  0.0           0  \n",
       "5169             0.0       0.0       0.0  0.000000  0.0           1  \n",
       "5170             0.0       0.0       0.0  0.001269  0.0           1  \n",
       "5171             0.0       0.0       0.0  0.000000  0.0           0  \n",
       "\n",
       "[5172 rows x 3001 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_rel = emails.T\n",
    "for col in emails_rel.columns:\n",
    "    if emails_rel[col].sum() > 0:\n",
    "        emails_rel[col] = emails_rel[col] / emails_rel[col].sum()\n",
    "emails_rel = emails_rel.T\n",
    "emails_rel[target] = (emails_rel[target] > 0).astype(int)\n",
    "emails_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28dfea-e312-4e59-813e-3ef86226f36d",
   "metadata": {},
   "source": [
    "Соотношение между классами таргета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f35da4-fc9a-458d-bdf1-cebed7572f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "0    3672\n",
       "1    1500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_rel[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d59e0-b00b-4b84-8b50-ff55b1bd7d84",
   "metadata": {},
   "source": [
    "Писем, которые необходимо отмечать как спам, более чем в 2 раза меньше, чем обычных. В случае сильного дисбаланса в классах таргета необходимо в первую очередь уменьшать вероятность FN-исхода, то есть оптимизировать метрику Recall. Поскольку идентификация спама не является критической задачей и данный класс не редок в данных - можно в качестве основных метрих при дальнейшем обучении, помимо матрицы ошибок и LogLoss, использовать F1-меру или P4-меру. Далее при проверках качества на тестовых данных будут рассчитываться дополнительные метрики: Precision, Recall, Specificity, NPV, F1-мера и P4-мера.\n",
    "\n",
    "### Основные метрики\n",
    "Функции для расчёта выбранных метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f86e0906-179a-4a02-819d-23f599813ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(tn, fp, fn, tp):\n",
    "    return round(tp / (tp + fp + 1e-15), 6)\n",
    "def Recall(tn, fp, fn, tp):\n",
    "    return round(tp / (tp + fn + 1e-15), 6)\n",
    "def Specificity(tn, fp, fn, tp):\n",
    "    return round(tn / (tn + fp + 1e-15), 6)\n",
    "def NPV(tn, fp, fn, tp):\n",
    "    return round(fn / (tn + fn + 1e-15), 6)\n",
    "def F1_score(tn, fp, fn, tp):\n",
    "    return round(2 * tp / (2 * tp + fp + fn + 1e-15), 6)\n",
    "def P4_score(tn, fp, fn, tp):\n",
    "    return round(4 * tp * tn / (4 * tp * tn + (tp + tn) * (fp + fn) + 1e-15), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dbd835-f8cd-41db-adcd-f6fec624d8b7",
   "metadata": {},
   "source": [
    "### Проверка на мультиколлинеарность\n",
    "Создание матрицы линейных корреляций между всеми параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd85030-57aa-4939-b365-fe0118c337d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132237</td>\n",
       "      <td>-0.209296</td>\n",
       "      <td>0.241947</td>\n",
       "      <td>-0.113356</td>\n",
       "      <td>0.188543</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>0.040086</td>\n",
       "      <td>0.031083</td>\n",
       "      <td>0.174598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>-0.011154</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>-0.007410</td>\n",
       "      <td>0.047613</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>-0.205290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.132237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.141674</td>\n",
       "      <td>0.084689</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>0.084524</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.096734</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011684</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>-0.002134</td>\n",
       "      <td>-0.011417</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.100499</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>-0.022319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ect</th>\n",
       "      <td>-0.209296</td>\n",
       "      <td>-0.141674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.205800</td>\n",
       "      <td>0.056344</td>\n",
       "      <td>-0.182165</td>\n",
       "      <td>-0.301343</td>\n",
       "      <td>-0.101627</td>\n",
       "      <td>0.281770</td>\n",
       "      <td>-0.242091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036244</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.011789</td>\n",
       "      <td>-0.023185</td>\n",
       "      <td>-0.021143</td>\n",
       "      <td>-0.001050</td>\n",
       "      <td>-0.024470</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>-0.014875</td>\n",
       "      <td>-0.053163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.241947</td>\n",
       "      <td>0.084689</td>\n",
       "      <td>-0.205800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.175017</td>\n",
       "      <td>0.141157</td>\n",
       "      <td>0.202622</td>\n",
       "      <td>0.084372</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.189041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018218</td>\n",
       "      <td>-0.019401</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.037164</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.034451</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>0.100608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>-0.113356</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>0.056344</td>\n",
       "      <td>-0.175017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.179038</td>\n",
       "      <td>-0.133723</td>\n",
       "      <td>-0.126104</td>\n",
       "      <td>-0.065897</td>\n",
       "      <td>-0.328211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013864</td>\n",
       "      <td>-0.037299</td>\n",
       "      <td>-0.020390</td>\n",
       "      <td>-0.030221</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>-0.010654</td>\n",
       "      <td>-0.163336</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>-0.282937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>-0.007410</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>-0.001050</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>-0.006750</td>\n",
       "      <td>-0.030502</td>\n",
       "      <td>-0.014810</td>\n",
       "      <td>-0.010723</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>0.040624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allowing</th>\n",
       "      <td>0.047613</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>-0.024470</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>-0.010654</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>-0.008579</td>\n",
       "      <td>0.043836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>-0.003090</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.019792</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>-0.009367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff</th>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.100499</td>\n",
       "      <td>-0.053802</td>\n",
       "      <td>0.034451</td>\n",
       "      <td>-0.163336</td>\n",
       "      <td>0.346421</td>\n",
       "      <td>-0.047051</td>\n",
       "      <td>-0.022998</td>\n",
       "      <td>-0.075778</td>\n",
       "      <td>0.060514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012131</td>\n",
       "      <td>-0.011409</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>0.134444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry</th>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>-0.014875</td>\n",
       "      <td>-0.001694</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>-0.016274</td>\n",
       "      <td>-0.015706</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002003</td>\n",
       "      <td>-0.001569</td>\n",
       "      <td>-0.003181</td>\n",
       "      <td>0.020622</td>\n",
       "      <td>-0.002183</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>-0.205290</td>\n",
       "      <td>-0.022319</td>\n",
       "      <td>-0.053163</td>\n",
       "      <td>0.100608</td>\n",
       "      <td>-0.282937</td>\n",
       "      <td>0.213178</td>\n",
       "      <td>-0.005477</td>\n",
       "      <td>0.258054</td>\n",
       "      <td>-0.206188</td>\n",
       "      <td>0.170873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024264</td>\n",
       "      <td>-0.021352</td>\n",
       "      <td>0.023514</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>0.028285</td>\n",
       "      <td>0.040624</td>\n",
       "      <td>-0.009367</td>\n",
       "      <td>0.134444</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows × 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 the        to       ect       and       for        of  \\\n",
       "the         1.000000  0.132237 -0.209296  0.241947 -0.113356  0.188543   \n",
       "to          0.132237  1.000000 -0.141674  0.084689 -0.218774  0.084524   \n",
       "ect        -0.209296 -0.141674  1.000000 -0.205800  0.056344 -0.182165   \n",
       "and         0.241947  0.084689 -0.205800  1.000000 -0.175017  0.141157   \n",
       "for        -0.113356 -0.218774  0.056344 -0.175017  1.000000 -0.179038   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "military   -0.007410  0.019581 -0.001050 -0.011392  0.020009 -0.006750   \n",
       "allowing    0.047613  0.010105 -0.024470  0.012603 -0.010654  0.009345   \n",
       "ff          0.022046  0.100499 -0.053802  0.034451 -0.163336  0.346421   \n",
       "dry         0.008755  0.008857 -0.014875 -0.001694  0.015542  0.008363   \n",
       "Prediction -0.205290 -0.022319 -0.053163  0.100608 -0.282937  0.213178   \n",
       "\n",
       "                   a       you       hou        in  ...  connevey       jay  \\\n",
       "the         0.066889  0.040086  0.031083  0.174598  ... -0.021946 -0.007979   \n",
       "to          0.005821  0.096734 -0.000460  0.134113  ... -0.011684  0.023168   \n",
       "ect        -0.301343 -0.101627  0.281770 -0.242091  ...  0.036244 -0.001368   \n",
       "and         0.202622  0.084372  0.002176  0.189041  ... -0.018218 -0.019401   \n",
       "for        -0.133723 -0.126104 -0.065897 -0.328211  ... -0.013864 -0.037299   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "military   -0.030502 -0.014810 -0.010723  0.015218  ... -0.001012 -0.001543   \n",
       "allowing   -0.009946  0.017027 -0.008579  0.043836  ... -0.001946 -0.002967   \n",
       "ff         -0.047051 -0.022998 -0.075778  0.060514  ... -0.012131 -0.011409   \n",
       "dry        -0.016274 -0.015706  0.004115  0.009105  ... -0.002003 -0.001569   \n",
       "Prediction -0.005477  0.258054 -0.206188  0.170873  ... -0.024264 -0.021352   \n",
       "\n",
       "              valued       lay  infrastructure  military  allowing        ff  \\\n",
       "the         0.044491 -0.011154        0.011928 -0.007410  0.047613  0.022046   \n",
       "to          0.023457 -0.002134       -0.011417  0.019581  0.010105  0.100499   \n",
       "ect        -0.011789 -0.023185       -0.021143 -0.001050 -0.024470 -0.053802   \n",
       "and         0.011943  0.002252        0.037164 -0.011392  0.012603  0.034451   \n",
       "for        -0.020390 -0.030221        0.007018  0.020009 -0.010654 -0.163336   \n",
       "...              ...       ...             ...       ...       ...       ...   \n",
       "military   -0.000389  0.002219       -0.000517  1.000000 -0.000959 -0.005085   \n",
       "allowing   -0.003090 -0.000628        0.019792 -0.000959  1.000000 -0.009688   \n",
       "ff          0.042433  0.037171        0.007839 -0.005085 -0.009688  1.000000   \n",
       "dry        -0.003181  0.020622       -0.002183 -0.001178 -0.002705  0.016999   \n",
       "Prediction  0.023514  0.057884        0.028285  0.040624 -0.009367  0.134444   \n",
       "\n",
       "                 dry  Prediction  \n",
       "the         0.008755   -0.205290  \n",
       "to          0.008857   -0.022319  \n",
       "ect        -0.014875   -0.053163  \n",
       "and        -0.001694    0.100608  \n",
       "for         0.015542   -0.282937  \n",
       "...              ...         ...  \n",
       "military   -0.001178    0.040624  \n",
       "allowing   -0.002705   -0.009367  \n",
       "ff          0.016999    0.134444  \n",
       "dry         1.000000   -0.014425  \n",
       "Prediction -0.014425    1.000000  \n",
       "\n",
       "[3001 rows x 3001 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multicorr = emails_rel.corr()\n",
    "multicorr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddda34f-e79b-4fb9-892a-16f822a70864",
   "metadata": {},
   "source": [
    "Список пар признаков, линейная корреляция которых превышает 0.4 по модулю. В случае, если качество обучения моделей будет недостаточным - можно поднять порог отсечения признаков для меньшего количества последующих удалений признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dad4d97-027b-4aea-a675-4a447efee40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пар: 3667\n",
      "Первые 5 пар: [('this', 'is'), ('enron', 'on'), ('i', 'for'), ('i', 'in'), ('your', 'you')]\n"
     ]
    }
   ],
   "source": [
    "mc_couples = list()\n",
    "mc_threshold = 0.4\n",
    "for i in range(1, multicorr.shape[0] - 1):\n",
    "    for j in range(i):\n",
    "        if abs(multicorr.iloc[i, j]) > mc_threshold:\n",
    "            mc_couples.append((multicorr.index[i], multicorr.index[j]))\n",
    "print('Количество пар:', len(mc_couples))\n",
    "print('Первые 5 пар:', mc_couples[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf72f43-3216-4fc5-af5b-c696f63c8ff7",
   "metadata": {},
   "source": [
    "Формирование множества признаков на удаление, которые имеют максимальную суммарную корреляцию с остальными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c9847e-4302-4b2e-9bc5-08804c5b6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количесвто признаков на удаление: 1343\n"
     ]
    }
   ],
   "source": [
    "feats_del = set()\n",
    "mc_couples_copy = [el for el in mc_couples]\n",
    "while len(mc_couples_copy) > 0:\n",
    "    feat_1 = mc_couples_copy[0][0]\n",
    "    feat_2 = mc_couples_copy[0][1]\n",
    "    corr_sum_1 = multicorr[feat_1].abs().sum()\n",
    "    corr_sum_2 = multicorr[feat_2].abs().sum()\n",
    "    feat_del = feat_1 if corr_sum_1 > corr_sum_2 else feat_2\n",
    "    feats_del.add(feat_del)\n",
    "    mc_couples_copy = [el for el in mc_couples_copy if feat_del not in el]\n",
    "print('Количесвто признаков на удаление:', len(feats_del))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83bfa8-db66-4019-a6ba-8a45b33af399",
   "metadata": {},
   "source": [
    "Удаление лишних признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352e1f1d-bb50-4588-a856-b4a22dd26f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to</th>\n",
       "      <th>a</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>this</th>\n",
       "      <th>be</th>\n",
       "      <th>that</th>\n",
       "      <th>have</th>\n",
       "      <th>with</th>\n",
       "      <th>your</th>\n",
       "      <th>...</th>\n",
       "      <th>remains</th>\n",
       "      <th>ifhsc</th>\n",
       "      <th>enhancements</th>\n",
       "      <th>connevey</th>\n",
       "      <th>valued</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.050049</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.053023</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.051378</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.054472</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5172 rows × 1658 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            to         a       hou        in      this        be      that  \\\n",
       "0     0.000000  0.037736  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.005901  0.046300  0.012256  0.008171  0.000000  0.001816  0.000908   \n",
       "2     0.000000  0.070796  0.000000  0.035398  0.000000  0.000000  0.000000   \n",
       "3     0.004907  0.050049  0.009814  0.000981  0.001963  0.001963  0.000000   \n",
       "4     0.005581  0.053023  0.008372  0.002791  0.001860  0.007442  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5167  0.003960  0.063366  0.000000  0.009901  0.000000  0.001980  0.000000   \n",
       "5168  0.009187  0.051378  0.001021  0.007826  0.001021  0.003403  0.002042   \n",
       "5169  0.000000  0.061453  0.000000  0.005587  0.005587  0.000000  0.000000   \n",
       "5170  0.008883  0.035533  0.000000  0.010152  0.001269  0.001269  0.000000   \n",
       "5171  0.008833  0.054472  0.000736  0.008465  0.001472  0.002208  0.001472   \n",
       "\n",
       "          have      with      your  ...  remains  ifhsc  enhancements  \\\n",
       "0     0.000000  0.000000  0.000000  ...      0.0    0.0           0.0   \n",
       "1     0.000000  0.000908  0.000000  ...      0.0    0.0           0.0   \n",
       "2     0.000000  0.000000  0.000000  ...      0.0    0.0           0.0   \n",
       "3     0.000981  0.000981  0.000000  ...      0.0    0.0           0.0   \n",
       "4     0.001860  0.000000  0.000000  ...      0.0    0.0           0.0   \n",
       "...        ...       ...       ...  ...      ...    ...           ...   \n",
       "5167  0.001980  0.000000  0.000000  ...      0.0    0.0           0.0   \n",
       "5168  0.000681  0.002042  0.000340  ...      0.0    0.0           0.0   \n",
       "5169  0.000000  0.000000  0.000000  ...      0.0    0.0           0.0   \n",
       "5170  0.000000  0.002538  0.001269  ...      0.0    0.0           0.0   \n",
       "5171  0.000368  0.000368  0.000368  ...      0.0    0.0           0.0   \n",
       "\n",
       "      connevey  valued  infrastructure  military  allowing  dry  Prediction  \n",
       "0          0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "1          0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "2          0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "3          0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "4          0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "...        ...     ...             ...       ...       ...  ...         ...  \n",
       "5167       0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "5168       0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "5169       0.0     0.0             0.0       0.0       0.0  0.0           1  \n",
       "5170       0.0     0.0             0.0       0.0       0.0  0.0           1  \n",
       "5171       0.0     0.0             0.0       0.0       0.0  0.0           0  \n",
       "\n",
       "[5172 rows x 1658 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_rel_corr = emails_rel.drop(columns = feats_del)\n",
    "emails_rel_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656d00f-1f90-4140-99ff-6c04862f62fa",
   "metadata": {},
   "source": [
    "### Разделение переменных\n",
    "Разделение данных из таблицы \"emails_rel_corr\" на независимые переменные (признаки) и зависимую переменную (таргет)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785080e1-e5d8-4aa9-90da-75b10a67b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = emails_rel_corr.drop(columns = [target])\n",
    "y = emails_rel_corr[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb7273-beda-47a5-9eb8-7988614b2df8",
   "metadata": {},
   "source": [
    "Разделение данных на train\\test в пропорции 80%/20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21eb5e4e-13da-4e9a-ac72-236b6b3c130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf2402-5d65-47a2-b311-074271bbcf90",
   "metadata": {},
   "source": [
    "## Обучение одиночных моделей\n",
    "Формирование словаря с самыми разнообразными одиночными моделями классификации и различными их гиперпараметрами для последующей тренировки и их сравнения. Гиперпараметры (количество итераций) выбраны таким образом, чтобы все модели успевали обучаться за разумное время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef151da8-654a-4deb-806a-8b8d5d964417",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_models = {\n",
    "    'LogisticRegression_l2_lbfgs': LogisticRegression(l1_ratio = 0, solver = 'lbfgs', random_state = random_seed),\n",
    "    'LogisticRegression_l1_liblinear': LogisticRegression(l1_ratio = 1, solver = 'liblinear', random_state = random_seed),\n",
    "    'LogisticRegression_l2_liblinear': LogisticRegression(l1_ratio = 0, solver = 'liblinear', random_state = random_seed),\n",
    "    'LogisticRegression_l2_newton-cg': LogisticRegression(l1_ratio = 0, solver = 'newton-cg', random_state = random_seed),\n",
    "    'LogisticRegression_l2_newton-ch': LogisticRegression(l1_ratio = 0, solver = 'newton-cholesky', random_state = random_seed),\n",
    "    'LogisticRegression_l2_sag': LogisticRegression(l1_ratio = 0, solver = 'sag', random_state = random_seed),\n",
    "    'LogisticRegression_l1_saga': LogisticRegression(l1_ratio = 1, solver = 'saga', random_state = random_seed, max_iter = 500),\n",
    "    'LogisticRegression_l2_saga': LogisticRegression(l1_ratio = 0, solver = 'saga', random_state = random_seed),\n",
    "    'Perceptron_l1': Perceptron(penalty = 'l1', random_state = random_seed, n_jobs = -1),\n",
    "    'Perceptron_l2': Perceptron(penalty = 'l2', random_state = random_seed, n_jobs = -1),\n",
    "    'RidgeClassifier_svd': RidgeClassifier(solver = 'svd', random_state = random_seed),\n",
    "    'RidgeClassifier_ch': RidgeClassifier(solver = 'cholesky', random_state = random_seed),\n",
    "    'RidgeClassifier_lsqr': RidgeClassifier(solver = 'lsqr', random_state = random_seed),\n",
    "    'RidgeClassifier_sc': RidgeClassifier(solver = 'sparse_cg', random_state = random_seed),\n",
    "    'RidgeClassifier_sag': RidgeClassifier(solver = 'sag', random_state = random_seed),\n",
    "    'RidgeClassifier_saga': RidgeClassifier(solver = 'saga', random_state = random_seed),\n",
    "    'RidgeClassifier_lbfgs': RidgeClassifier(solver = 'lbfgs', positive = True, random_state = random_seed),\n",
    "    'SGDClassifier_hinge': SGDClassifier(loss = 'hinge', random_state = random_seed, n_jobs = -1),\n",
    "    'SGDClassifier_ll': SGDClassifier(loss = 'log_loss', random_state = random_seed, n_jobs = -1),\n",
    "    'SGDClassifier_mh': SGDClassifier(loss = 'modified_huber', random_state = random_seed, n_jobs = -1),\n",
    "    'SGDClassifier_perceptron': SGDClassifier(loss = 'perceptron', random_state = random_seed, n_jobs = -1),\n",
    "    'SGDClassifier_ei': SGDClassifier(loss = 'epsilon_insensitive', random_state = random_seed, n_jobs = -1),\n",
    "    'BernoulliNB': BernoulliNB(), 'CategoricalNB': CategoricalNB(), 'ComplementNB': ComplementNB(),\n",
    "    'GaussianNB': GaussianNB(), 'MultinomialNB': MultinomialNB(),\n",
    "    'KNeighborsClassifier_u_bt': KNeighborsClassifier(weights = 'uniform', algorithm = 'ball_tree', n_jobs = -1),\n",
    "    'KNeighborsClassifier_d_bt': KNeighborsClassifier(weights = 'distance', algorithm = 'ball_tree', n_jobs = -1),\n",
    "    'KNeighborsClassifier_u_kdt': KNeighborsClassifier(weights = 'uniform', algorithm = 'kd_tree', n_jobs = -1),\n",
    "    'KNeighborsClassifier_d_kdt': KNeighborsClassifier(weights = 'distance', algorithm = 'kd_tree', n_jobs = -1),\n",
    "    'KNeighborsClassifier_u_b': KNeighborsClassifier(weights = 'uniform', algorithm = 'brute', n_jobs = -1),\n",
    "    'KNeighborsClassifier_d_b': KNeighborsClassifier(weights = 'distance', algorithm = 'brute', n_jobs = -1),\n",
    "    'NearestCentroid_e': NearestCentroid(metric = 'euclidean'),\n",
    "    'NearestCentroid_m': NearestCentroid(metric = 'manhattan'),\n",
    "    'RadiusNeighborsClassifier_u_bt': RadiusNeighborsClassifier(weights = 'uniform', algorithm = 'ball_tree', n_jobs = -1),\n",
    "    'RadiusNeighborsClassifier_d_bt': RadiusNeighborsClassifier(weights = 'distance', algorithm = 'ball_tree', n_jobs = -1),\n",
    "    'RadiusNeighborsClassifier_u_kdt': RadiusNeighborsClassifier(weights = 'uniform', algorithm = 'kd_tree', n_jobs = -1),\n",
    "    'RadiusNeighborsClassifier_d_kdt': RadiusNeighborsClassifier(weights = 'distance', algorithm = 'kd_tree', n_jobs = -1),\n",
    "    'RadiusNeighborsClassifier_u_b': RadiusNeighborsClassifier(weights = 'uniform', algorithm = 'brute', n_jobs = -1),\n",
    "    'RadiusNeighborsClassifier_d_b': RadiusNeighborsClassifier(weights = 'distance', algorithm = 'brute', n_jobs = -1),\n",
    "    'MLPClassifier_l_lbfgs': MLPClassifier(activation = 'logistic', solver = 'lbfgs', random_state = random_seed),\n",
    "    'MLPClassifier_l_sgd': MLPClassifier(activation = 'logistic', solver = 'sgd', random_state = random_seed),\n",
    "    'MLPClassifier_l_adam': MLPClassifier(activation = 'logistic', solver = 'adam', random_state = random_seed, max_iter = 2000),\n",
    "    'MLPClassifier_t_lbfgs': MLPClassifier(activation = 'tanh', solver = 'lbfgs', random_state = random_seed, max_iter = 2000),\n",
    "    'MLPClassifier_t_sgd': MLPClassifier(activation = 'tanh', solver = 'sgd', random_state = random_seed),\n",
    "    'MLPClassifier_t_adam': MLPClassifier(activation = 'tanh', solver = 'adam', random_state = random_seed, max_iter = 1000),\n",
    "    'LinearSVC_l2_hinge': LinearSVC(penalty = 'l2', loss = 'hinge',\n",
    "                                    class_weight = 'balanced', random_state = random_seed),\n",
    "    'LinearSVC_l1_shinge': LinearSVC(penalty = 'l1', loss = 'squared_hinge',\n",
    "                                     class_weight = 'balanced', random_state = random_seed, max_iter = 5000),\n",
    "    'LinearSVC_l2_shinge': LinearSVC(penalty = 'l2', loss = 'squared_hinge',\n",
    "                                     class_weight = 'balanced', random_state = random_seed),\n",
    "    'NuSVC_linear': NuSVC(kernel = 'linear', class_weight = 'balanced', random_state = random_seed),\n",
    "    'NuSVC_poly': NuSVC(kernel = 'poly', class_weight = 'balanced', random_state = random_seed),\n",
    "    'NuSVC_rbf': NuSVC(kernel = 'rbf', class_weight = 'balanced', random_state = random_seed),\n",
    "    'NuSVC_sigmoid': NuSVC(kernel = 'sigmoid', class_weight = 'balanced', random_state = random_seed),\n",
    "    'SVC_linear': SVC(kernel = 'linear', class_weight = 'balanced', random_state = random_seed),\n",
    "    'SVC_poly': SVC(kernel = 'poly', class_weight = 'balanced', random_state = random_seed),\n",
    "    'SVC_rbf': SVC(kernel = 'rbf', class_weight = 'balanced', random_state = random_seed),\n",
    "    'SVC_sigmoid': SVC(kernel = 'sigmoid', class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_gini_3': DecisionTreeClassifier(criterion = 'gini', max_depth = 3,\n",
    "                                                            class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_entr_3': DecisionTreeClassifier(criterion = 'entropy', max_depth = 3,\n",
    "                                                            class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_ll_3': DecisionTreeClassifier(criterion = 'log_loss', max_depth = 3,\n",
    "                                                          class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_gini_7': DecisionTreeClassifier(criterion = 'gini', max_depth = 7,\n",
    "                                                            class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_entr_7': DecisionTreeClassifier(criterion = 'entropy', max_depth = 7,\n",
    "                                                            class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_ll_7': DecisionTreeClassifier(criterion = 'log_loss', max_depth = 7,\n",
    "                                                          class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_gini_11': DecisionTreeClassifier(criterion = 'gini', max_depth = 11,\n",
    "                                                             class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_entr_11': DecisionTreeClassifier(criterion = 'entropy', max_depth = 11,\n",
    "                                                             class_weight = 'balanced', random_state = random_seed),\n",
    "    'DecisionTreeClassifier_ll_11': DecisionTreeClassifier(criterion = 'log_loss', max_depth = 11,\n",
    "                                                           class_weight = 'balanced', random_state = random_seed)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838de9f3-e769-417e-82d3-59a1b2799606",
   "metadata": {},
   "source": [
    "Тренировка всех моделей из \"skl_models\" в отдельном словаре \"skl_models_fit\" с отслеживанием времени обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9de38c5-4c60-4def-ba64-cd75aaba3295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LogisticRegression_l2_lbfgs\", 0.10333160002483055 секунд\n",
      "\"LogisticRegression_l1_liblinear\", 0.18345930002396926 секунд\n",
      "\"LogisticRegression_l2_liblinear\", 0.07832799997413531 секунд\n",
      "\"LogisticRegression_l2_newton-cg\", 0.20281549997162074 секунд\n",
      "\"LogisticRegression_l2_newton-ch\", 0.9815825000405312 секунд\n",
      "\"LogisticRegression_l2_sag\", 1.8793279999517836 секунд\n",
      "\"LogisticRegression_l1_saga\", 24.533505700004753 секунд\n",
      "\"LogisticRegression_l2_saga\", 1.2664906999561936 секунд\n",
      "\"Perceptron_l1\", 0.5369838000042364 секунд\n",
      "\"Perceptron_l2\", 0.21678499999688938 секунд\n",
      "\"RidgeClassifier_svd\", 3.398872699995991 секунд\n",
      "\"RidgeClassifier_ch\", 0.2848760999622755 секунд\n",
      "\"RidgeClassifier_lsqr\", 0.12153780000517145 секунд\n",
      "\"RidgeClassifier_sc\", 0.12403920001816005 секунд\n",
      "\"RidgeClassifier_sag\", 0.7925771999871358 секунд\n",
      "\"RidgeClassifier_saga\", 1.3019705000333488 секунд\n",
      "\"RidgeClassifier_lbfgs\", 0.11985809996258467 секунд\n",
      "\"SGDClassifier_hinge\", 0.6984234999981709 секунд\n",
      "\"SGDClassifier_ll\", 0.5851261999923736 секунд\n",
      "\"SGDClassifier_mh\", 1.3143206000095233 секунд\n",
      "\"SGDClassifier_perceptron\", 0.4873745999648236 секунд\n",
      "\"SGDClassifier_ei\", 0.868729300040286 секунд\n",
      "\"BernoulliNB\", 0.2006973999668844 секунд\n",
      "\"CategoricalNB\", 0.20809660002123564 секунд\n",
      "\"ComplementNB\", 0.021067399997264147 секунд\n",
      "\"GaussianNB\", 0.13274939998518676 секунд\n",
      "\"MultinomialNB\", 0.019984400016255677 секунд\n",
      "\"KNeighborsClassifier_u_bt\", 0.6506803000229411 секунд\n",
      "\"KNeighborsClassifier_d_bt\", 0.6482102000154555 секунд\n",
      "\"KNeighborsClassifier_u_kdt\", 1.0129346000030637 секунд\n",
      "\"KNeighborsClassifier_d_kdt\", 1.0738907000049949 секунд\n",
      "\"KNeighborsClassifier_u_b\", 0.03719420003471896 секунд\n",
      "\"KNeighborsClassifier_d_b\", 0.04484390001744032 секунд\n",
      "\"NearestCentroid_e\", 0.16471819998696446 секунд\n",
      "\"NearestCentroid_m\", 0.27429319999646395 секунд\n",
      "\"RadiusNeighborsClassifier_u_bt\", 0.71747360000154 секунд\n",
      "\"RadiusNeighborsClassifier_d_bt\", 0.7204172000056133 секунд\n",
      "\"RadiusNeighborsClassifier_u_kdt\", 1.13376190001145 секунд\n",
      "\"RadiusNeighborsClassifier_d_kdt\", 1.1768962999922223 секунд\n",
      "\"RadiusNeighborsClassifier_u_b\", 0.05898410000372678 секунд\n",
      "\"RadiusNeighborsClassifier_d_b\", 0.05694109998876229 секунд\n",
      "\"MLPClassifier_l_lbfgs\", 0.433693700004369 секунд\n",
      "\"MLPClassifier_l_sgd\", 7.045107600046322 секунд\n",
      "\"MLPClassifier_l_adam\", 604.3849224000005 секунд\n",
      "\"MLPClassifier_t_lbfgs\", 198.59899640001822 секунд\n",
      "\"MLPClassifier_t_sgd\", 11.051943400001619 секунд\n",
      "\"MLPClassifier_t_adam\", 271.41069479996804 секунд\n",
      "\"LinearSVC_l2_hinge\", 0.08438650000607595 секунд\n",
      "\"LinearSVC_l1_shinge\", 1.5502750999876298 секунд\n",
      "\"LinearSVC_l2_shinge\", 0.091323199972976 секунд\n",
      "\"NuSVC_linear\", 11.94784909998998 секунд\n",
      "\"NuSVC_poly\", 13.305991999979597 секунд\n",
      "\"NuSVC_rbf\", 12.037250399996992 секунд\n",
      "\"NuSVC_sigmoid\", 13.040183999983128 секунд\n",
      "\"SVC_linear\", 17.79828509996878 секунд\n",
      "\"SVC_poly\", 9.736024199984968 секунд\n",
      "\"SVC_rbf\", 10.725150100013707 секунд\n",
      "\"SVC_sigmoid\", 13.87146340002073 секунд\n",
      "\"DecisionTreeClassifier_gini_3\", 0.2535644000163302 секунд\n",
      "\"DecisionTreeClassifier_entr_3\", 0.2733178999624215 секунд\n",
      "\"DecisionTreeClassifier_ll_3\", 0.3172424000222236 секунд\n",
      "\"DecisionTreeClassifier_gini_7\", 0.5694625999894924 секунд\n",
      "\"DecisionTreeClassifier_entr_7\", 0.6868429000023752 секунд\n",
      "\"DecisionTreeClassifier_ll_7\", 0.6088548999978229 секунд\n",
      "\"DecisionTreeClassifier_gini_11\", 0.9161567999981344 секунд\n",
      "\"DecisionTreeClassifier_entr_11\", 1.0413377999793738 секунд\n",
      "\"DecisionTreeClassifier_ll_11\", 1.1241787999751978 секунд\n",
      "Суммарное время обучения моделей: 1251.361580799974 секунд\n"
     ]
    }
   ],
   "source": [
    "skl_models_fit = dict()\n",
    "start = time.perf_counter()\n",
    "for model in skl_models:\n",
    "    time1 = time.perf_counter()\n",
    "    skl_models_fit[model] = skl_models[model].fit(X_train, y_train)\n",
    "    print(f'\"{model}\", {time.perf_counter() - time1} секунд')\n",
    "print('Суммарное время обучения моделей:', time.perf_counter() - start, 'секунд')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731209ed-d300-49fd-bb23-13624cab8fe7",
   "metadata": {},
   "source": [
    "Расчёт элементов матрицы ошибок и метрики LogLoss для каждой модели из \"skl_models_fit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f82df0-6b78-4603-962c-fb9772948da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_m = dict()\n",
    "fp_m = dict()\n",
    "fn_m = dict()\n",
    "tp_m = dict()\n",
    "logloss_m = dict()\n",
    "for model in skl_models_fit:\n",
    "    y_pred = skl_models_fit[model].predict(X_test)\n",
    "    (tn, fp, fn, tp) = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel().tolist()\n",
    "    tn_m[model], fp_m[model], fn_m[model], tp_m[model] = tn, fp, fn, tp\n",
    "    logloss_m[model] = log_loss(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16852133-97bc-4ef0-954e-5ace986d2872",
   "metadata": {},
   "source": [
    "Расчёт метрик на тестовых данных и формирование общей таблицы с её сохранением, где индекс - модель, столбец - метрика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f9ec5eb-a5e0-4ceb-bb64-e7dceb9d43bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_lbfgs</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l1_liblinear</th>\n",
       "      <td>704.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.064363</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.132911</td>\n",
       "      <td>0.979138</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.354250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_liblinear</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_newton-cg</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_newton-ch</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier_entr_7</th>\n",
       "      <td>535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>7.870402</td>\n",
       "      <td>0.598253</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.072790</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.762304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier_ll_7</th>\n",
       "      <td>535.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>7.870402</td>\n",
       "      <td>0.598253</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.072790</td>\n",
       "      <td>0.708010</td>\n",
       "      <td>0.762304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier_gini_11</th>\n",
       "      <td>625.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>5.397842</td>\n",
       "      <td>0.730659</td>\n",
       "      <td>0.806962</td>\n",
       "      <td>0.869263</td>\n",
       "      <td>0.088921</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.823750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier_entr_11</th>\n",
       "      <td>620.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>5.780914</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.787975</td>\n",
       "      <td>0.862309</td>\n",
       "      <td>0.097525</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.810634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier_ll_11</th>\n",
       "      <td>620.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>5.780914</td>\n",
       "      <td>0.715517</td>\n",
       "      <td>0.787975</td>\n",
       "      <td>0.862309</td>\n",
       "      <td>0.097525</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.810634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    TN     FP     FN     TP    LogLoss  \\\n",
       "LogisticRegression_l2_lbfgs      719.0    0.0  316.0    0.0  11.004632   \n",
       "LogisticRegression_l1_liblinear  704.0   15.0  274.0   42.0  10.064363   \n",
       "LogisticRegression_l2_liblinear  719.0    0.0  316.0    0.0  11.004632   \n",
       "LogisticRegression_l2_newton-cg  719.0    0.0  316.0    0.0  11.004632   \n",
       "LogisticRegression_l2_newton-ch  719.0    0.0  316.0    0.0  11.004632   \n",
       "...                                ...    ...    ...    ...        ...   \n",
       "DecisionTreeClassifier_entr_7    535.0  184.0   42.0  274.0   7.870402   \n",
       "DecisionTreeClassifier_ll_7      535.0  184.0   42.0  274.0   7.870402   \n",
       "DecisionTreeClassifier_gini_11   625.0   94.0   61.0  255.0   5.397842   \n",
       "DecisionTreeClassifier_entr_11   620.0   99.0   67.0  249.0   5.780914   \n",
       "DecisionTreeClassifier_ll_11     620.0   99.0   67.0  249.0   5.780914   \n",
       "\n",
       "                                 Precision    Recall  Specificity       NPV  \\\n",
       "LogisticRegression_l2_lbfgs       0.000000  0.000000     1.000000  0.305314   \n",
       "LogisticRegression_l1_liblinear   0.736842  0.132911     0.979138  0.280164   \n",
       "LogisticRegression_l2_liblinear   0.000000  0.000000     1.000000  0.305314   \n",
       "LogisticRegression_l2_newton-cg   0.000000  0.000000     1.000000  0.305314   \n",
       "LogisticRegression_l2_newton-ch   0.000000  0.000000     1.000000  0.305314   \n",
       "...                                    ...       ...          ...       ...   \n",
       "DecisionTreeClassifier_entr_7     0.598253  0.867089     0.744089  0.072790   \n",
       "DecisionTreeClassifier_ll_7       0.598253  0.867089     0.744089  0.072790   \n",
       "DecisionTreeClassifier_gini_11    0.730659  0.806962     0.869263  0.088921   \n",
       "DecisionTreeClassifier_entr_11    0.715517  0.787975     0.862309  0.097525   \n",
       "DecisionTreeClassifier_ll_11      0.715517  0.787975     0.862309  0.097525   \n",
       "\n",
       "                                 F1-score  P4-score  \n",
       "LogisticRegression_l2_lbfgs      0.000000  0.000000  \n",
       "LogisticRegression_l1_liblinear  0.225201  0.354250  \n",
       "LogisticRegression_l2_liblinear  0.000000  0.000000  \n",
       "LogisticRegression_l2_newton-cg  0.000000  0.000000  \n",
       "LogisticRegression_l2_newton-ch  0.000000  0.000000  \n",
       "...                                   ...       ...  \n",
       "DecisionTreeClassifier_entr_7    0.708010  0.762304  \n",
       "DecisionTreeClassifier_ll_7      0.708010  0.762304  \n",
       "DecisionTreeClassifier_gini_11   0.766917  0.823750  \n",
       "DecisionTreeClassifier_entr_11   0.750000  0.810634  \n",
       "DecisionTreeClassifier_ll_11     0.750000  0.810634  \n",
       "\n",
       "[67 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_m = pd.DataFrame([tn_m, fp_m, fn_m, tp_m, logloss_m], index = ['TN', 'FP', 'FN', 'TP', 'LogLoss']).T\n",
    "results_m['Precision'] = Precision(tn = results_m['TN'], fp = results_m['FP'], fn = results_m['FN'], tp = results_m['TP'])\n",
    "results_m['Recall'] = Recall(tn = results_m['TN'], fp = results_m['FP'], fn = results_m['FN'], tp = results_m['TP'])\n",
    "results_m['Specificity'] = Specificity(tn = results_m['TN'], fp = results_m['FP'], fn = results_m['FN'], tp = results_m['TP'])\n",
    "results_m['NPV'] = NPV(tn = results_m['TN'], fp = results_m['FP'], fn = results_m['FN'], tp = results_m['TP'])\n",
    "results_m['F1-score'] = F1_score(tn = results_m['TN'], fp = results_m['FP'], fn = results_m['FN'], tp = results_m['TP'])\n",
    "results_m['P4-score'] = P4_score(tn = results_m['TN'], fp = results_m['FP'], fn = results_m['FN'], tp = results_m['TP'])\n",
    "results_m.to_csv('results/results_models.csv', sep = ',', index_label = 'Single_models')\n",
    "results_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfdf43d-36ff-4f2f-b56e-2552ec54ab9c",
   "metadata": {},
   "source": [
    "Первые 10 лучших моделей по метрике LogLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5871a1e-fc63-432a-8810-63ee46d9f00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_lbfgs</th>\n",
       "      <td>1.427816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_adam</th>\n",
       "      <td>1.567115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_l_adam</th>\n",
       "      <td>2.054662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>2.785983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_poly</th>\n",
       "      <td>4.213799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC_rbf</th>\n",
       "      <td>4.562047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_kdt</th>\n",
       "      <td>4.596872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_bt</th>\n",
       "      <td>4.596872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_b</th>\n",
       "      <td>4.596872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC_poly</th>\n",
       "      <td>4.631697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             LogLoss\n",
       "MLPClassifier_t_lbfgs       1.427816\n",
       "MLPClassifier_t_adam        1.567115\n",
       "MLPClassifier_l_adam        2.054662\n",
       "GaussianNB                  2.785983\n",
       "SVC_poly                    4.213799\n",
       "NuSVC_rbf                   4.562047\n",
       "KNeighborsClassifier_d_kdt  4.596872\n",
       "KNeighborsClassifier_d_bt   4.596872\n",
       "KNeighborsClassifier_d_b    4.596872\n",
       "NuSVC_poly                  4.631697"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_m.sort_values(by = 'LogLoss')[:10][['LogLoss']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e4ea0-799b-40cb-8832-0d0f98ab9aef",
   "metadata": {},
   "source": [
    "Первые 10 лучших моделей по метрике F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03ddd027-5b4e-4b7c-bc64-0675836e0c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_lbfgs</th>\n",
       "      <td>0.934609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_adam</th>\n",
       "      <td>0.929356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_l_adam</th>\n",
       "      <td>0.906498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_poly</th>\n",
       "      <td>0.830295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_rbf</th>\n",
       "      <td>0.813793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_b</th>\n",
       "      <td>0.786408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_kdt</th>\n",
       "      <td>0.786408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_bt</th>\n",
       "      <td>0.786408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_u_bt</th>\n",
       "      <td>0.768233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            F1-score\n",
       "MLPClassifier_t_lbfgs       0.934609\n",
       "MLPClassifier_t_adam        0.929356\n",
       "MLPClassifier_l_adam        0.906498\n",
       "GaussianNB                  0.878049\n",
       "SVC_poly                    0.830295\n",
       "SVC_rbf                     0.813793\n",
       "KNeighborsClassifier_d_b    0.786408\n",
       "KNeighborsClassifier_d_kdt  0.786408\n",
       "KNeighborsClassifier_d_bt   0.786408\n",
       "KNeighborsClassifier_u_bt   0.768233"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_m.sort_values(by = 'F1-score', ascending = False)[:10][['F1-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f92a0-630b-4ff9-9608-cb27a9f4fc7c",
   "metadata": {},
   "source": [
    "Первые 10 лучших моделей по метрике P4-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967e7540-183b-4694-8d01-c271a4818c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_lbfgs</th>\n",
       "      <td>0.952739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_adam</th>\n",
       "      <td>0.948571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_l_adam</th>\n",
       "      <td>0.932010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.909563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_poly</th>\n",
       "      <td>0.868701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_rbf</th>\n",
       "      <td>0.854561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_b</th>\n",
       "      <td>0.843311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_kdt</th>\n",
       "      <td>0.843311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier_d_bt</th>\n",
       "      <td>0.843311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC_rbf</th>\n",
       "      <td>0.830216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            P4-score\n",
       "MLPClassifier_t_lbfgs       0.952739\n",
       "MLPClassifier_t_adam        0.948571\n",
       "MLPClassifier_l_adam        0.932010\n",
       "GaussianNB                  0.909563\n",
       "SVC_poly                    0.868701\n",
       "SVC_rbf                     0.854561\n",
       "KNeighborsClassifier_d_b    0.843311\n",
       "KNeighborsClassifier_d_kdt  0.843311\n",
       "KNeighborsClassifier_d_bt   0.843311\n",
       "NuSVC_rbf                   0.830216"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_m.sort_values(by = 'P4-score', ascending = False)[:10][['P4-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99181b-9b9c-4f87-9c88-b9ef71361434",
   "metadata": {},
   "source": [
    "Как видно, лучшими моделями являются многослойные персептроны (с одним скрытым слоем) и наивный байесовский классификатор. Данные результаты можно считать baseline-ом, который должны превзойти более сложные модели (ансамбли), рассматриваемые далее.\n",
    "\n",
    "## Обучение ансамблей моделей\n",
    "Формирование словаря с самыми разнообразными ансамблями для классификации и различными их гиперпараметрами для последующей тренировки и их сравнения. В данном случае не рассматриваются ансамбли на основе стекинга и воутинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fd9fec6-df4d-46a3-a3fb-062b93d4eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_ensembles = {\n",
    "    'AdaBoostClassifier_dt_3': AdaBoostClassifier(estimator = DecisionTreeClassifier(max_depth = 3),\n",
    "                                                  n_estimators = 100, random_state = random_seed),\n",
    "    'AdaBoostClassifier_dt_7': AdaBoostClassifier(estimator = DecisionTreeClassifier(max_depth = 7),\n",
    "                                                  n_estimators = 100, random_state = random_seed),\n",
    "    'AdaBoostClassifier_dt_11': AdaBoostClassifier(estimator = DecisionTreeClassifier(max_depth = 11),\n",
    "                                                   n_estimators = 100, random_state = random_seed),\n",
    "    'AdaBoostClassifier_gnb': AdaBoostClassifier(estimator = GaussianNB(), n_estimators = 100, random_state = random_seed),\n",
    "    'BaggingClassifier_dt_3': BaggingClassifier(estimator = DecisionTreeClassifier(max_depth = 3),\n",
    "                                                n_estimators = 100, n_jobs = -1, random_state = random_seed),\n",
    "    'BaggingClassifier_dt_7': BaggingClassifier(estimator = DecisionTreeClassifier(max_depth = 7),\n",
    "                                                n_estimators = 100, n_jobs = -1, random_state = random_seed),\n",
    "    'BaggingClassifier_dt_11': BaggingClassifier(estimator = DecisionTreeClassifier(max_depth = 11),\n",
    "                                                 n_estimators = 100, n_jobs = -1, random_state = random_seed),\n",
    "    'BaggingClassifier_gnb': BaggingClassifier(estimator = GaussianNB(), n_estimators = 100, n_jobs = -1, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_g_3': ExtraTreesClassifier(criterion = 'gini', max_depth = 3, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_g_7': ExtraTreesClassifier(criterion = 'gini', max_depth = 7, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_g_11': ExtraTreesClassifier(criterion = 'gini', max_depth = 11, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_e_3': ExtraTreesClassifier(criterion = 'entropy', max_depth = 3, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_e_7': ExtraTreesClassifier(criterion = 'entropy', max_depth = 7, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_e_11': ExtraTreesClassifier(criterion = 'entropy', max_depth = 11, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_ll_3': ExtraTreesClassifier(criterion = 'log_loss', max_depth = 3, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_ll_7': ExtraTreesClassifier(criterion = 'log_loss', max_depth = 7, random_state = random_seed),\n",
    "    'ExtraTreesClassifier_ll_11': ExtraTreesClassifier(criterion = 'log_loss', max_depth = 11, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_ll_fmse_3': GradientBoostingClassifier(loss = 'log_loss', criterion = 'friedman_mse',\n",
    "                                                                       max_depth = 3, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_ll_fmse_7': GradientBoostingClassifier(loss = 'log_loss', criterion = 'friedman_mse',\n",
    "                                                                       max_depth = 7, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_ll_fmse_11': GradientBoostingClassifier(loss = 'log_loss', criterion = 'friedman_mse',\n",
    "                                                                        max_depth = 11, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_ll_se_3': GradientBoostingClassifier(loss = 'log_loss', criterion = 'squared_error',\n",
    "                                                                     max_depth = 3, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_ll_se_7': GradientBoostingClassifier(loss = 'log_loss', criterion = 'squared_error',\n",
    "                                                                     max_depth = 7, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_ll_se_11': GradientBoostingClassifier(loss = 'log_loss', criterion = 'squared_error',\n",
    "                                                                      max_depth = 11, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_e_fmse_3': GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse',\n",
    "                                                                      max_depth = 3, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_e_fmse_7': GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse',\n",
    "                                                                      max_depth = 7, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_e_fmse_11': GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse',\n",
    "                                                                       max_depth = 11, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_e_se_3': GradientBoostingClassifier(loss = 'exponential', criterion = 'squared_error',\n",
    "                                                                    max_depth = 3, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_e_se_7': GradientBoostingClassifier(loss = 'exponential', criterion = 'squared_error',\n",
    "                                                                    max_depth = 7, random_state = random_seed),\n",
    "    'GradientBoostingClassifier_e_se_11': GradientBoostingClassifier(loss = 'exponential', criterion = 'squared_error',\n",
    "                                                                     max_depth = 11, random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_3_0': HistGradientBoostingClassifier(max_depth = 3, l2_regularization = 0,\n",
    "                                                                         class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_7_0': HistGradientBoostingClassifier(max_depth = 7, l2_regularization = 0,\n",
    "                                                                         class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_11_0': HistGradientBoostingClassifier(max_depth = 11, l2_regularization = 0,\n",
    "                                                                          class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_3_1': HistGradientBoostingClassifier(max_depth = 3, l2_regularization = 1,\n",
    "                                                                         class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_7_1': HistGradientBoostingClassifier(max_depth = 7, l2_regularization = 1,\n",
    "                                                                         class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_11_1': HistGradientBoostingClassifier(max_depth = 11, l2_regularization = 1,\n",
    "                                                                          class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_3_5': HistGradientBoostingClassifier(max_depth = 3, l2_regularization = 5,\n",
    "                                                                         class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_7_5': HistGradientBoostingClassifier(max_depth = 7, l2_regularization = 5,\n",
    "                                                                         class_weight = 'balanced', random_state = random_seed),\n",
    "    'HistGradientBoostingClassifier_11_5': HistGradientBoostingClassifier(max_depth = 11, l2_regularization = 5,\n",
    "                                                                          class_weight = 'balanced', random_state = random_seed),\n",
    "    'RandomForestClassifier_g_3': RandomForestClassifier(criterion = 'gini', max_depth = 3, n_jobs = -1,\n",
    "                                                         class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_g_7': RandomForestClassifier(criterion = 'gini', max_depth = 7, n_jobs = -1,\n",
    "                                                         class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_g_11': RandomForestClassifier(criterion = 'gini', max_depth = 11, n_jobs = -1,\n",
    "                                                          class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_e_3': RandomForestClassifier(criterion = 'entropy', max_depth = 3, n_jobs = -1,\n",
    "                                                         class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_e_7': RandomForestClassifier(criterion = 'entropy', max_depth = 7, n_jobs = -1,\n",
    "                                                         class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_e_11': RandomForestClassifier(criterion = 'entropy', max_depth = 11, n_jobs = -1,\n",
    "                                                          class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_ll_3': RandomForestClassifier(criterion = 'log_loss', max_depth = 3, n_jobs = -1,\n",
    "                                                          class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_ll_7': RandomForestClassifier(criterion = 'log_loss', max_depth = 7, n_jobs = -1,\n",
    "                                                          class_weight = 'balanced_subsample', random_state = random_seed),\n",
    "    'RandomForestClassifier_ll_11': RandomForestClassifier(criterion = 'log_loss', max_depth = 11, n_jobs = -1,\n",
    "                                                           class_weight = 'balanced_subsample', random_state = random_seed)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab5377f-d7b5-4bfe-aa62-43470283370a",
   "metadata": {},
   "source": [
    "Тренировка всех ансамблей из \"skl_ensembles\" в отдельном словаре \"skl_ensembles_fit\" с отслеживанием времени обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65d1a69b-d21c-48bc-ad34-a37084d51133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AdaBoostClassifier_dt_3\", 25.746884900028817 секунд\n",
      "\"AdaBoostClassifier_dt_7\", 53.72908720001578 секунд\n",
      "\"AdaBoostClassifier_dt_11\", 78.25236899999436 секунд\n",
      "\"AdaBoostClassifier_gnb\", 4.525244000018574 секунд\n",
      "\"BaggingClassifier_dt_3\", 11.099929800024256 секунд\n",
      "\"BaggingClassifier_dt_7\", 11.161335600016173 секунд\n",
      "\"BaggingClassifier_dt_11\", 14.836776100040879 секунд\n",
      "\"BaggingClassifier_gnb\", 9.087056499964092 секунд\n",
      "\"ExtraTreesClassifier_g_3\", 0.6784332999959588 секунд\n",
      "\"ExtraTreesClassifier_g_7\", 1.269481800030917 секунд\n",
      "\"ExtraTreesClassifier_g_11\", 1.4804608999984339 секунд\n",
      "\"ExtraTreesClassifier_e_3\", 0.5877670000190847 секунд\n",
      "\"ExtraTreesClassifier_e_7\", 1.1231015999801457 секунд\n",
      "\"ExtraTreesClassifier_e_11\", 1.5438555000000633 секунд\n",
      "\"ExtraTreesClassifier_ll_3\", 0.7542166999774054 секунд\n",
      "\"ExtraTreesClassifier_ll_7\", 1.1688002000446431 секунд\n",
      "\"ExtraTreesClassifier_ll_11\", 1.6594852000125684 секунд\n",
      "\"GradientBoostingClassifier_ll_fmse_3\", 19.4279366999981 секунд\n",
      "\"GradientBoostingClassifier_ll_fmse_7\", 47.02201990003232 секунд\n",
      "\"GradientBoostingClassifier_ll_fmse_11\", 102.3446782999672 секунд\n",
      "\"GradientBoostingClassifier_ll_se_3\", 19.518884300021455 секунд\n",
      "\"GradientBoostingClassifier_ll_se_7\", 49.87015440000687 секунд\n",
      "\"GradientBoostingClassifier_ll_se_11\", 76.42082929995377 секунд\n",
      "\"GradientBoostingClassifier_e_fmse_3\", 18.143232899950817 секунд\n",
      "\"GradientBoostingClassifier_e_fmse_7\", 45.424707300029695 секунд\n",
      "\"GradientBoostingClassifier_e_fmse_11\", 70.45451190002495 секунд\n",
      "\"GradientBoostingClassifier_e_se_3\", 18.63875049998751 секунд\n",
      "\"GradientBoostingClassifier_e_se_7\", 45.16369620000478 секунд\n",
      "\"GradientBoostingClassifier_e_se_11\", 69.62064060004195 секунд\n",
      "\"HistGradientBoostingClassifier_3_0\", 3.240304799983278 секунд\n",
      "\"HistGradientBoostingClassifier_7_0\", 7.955109899980016 секунд\n",
      "\"HistGradientBoostingClassifier_11_0\", 10.181836100004148 секунд\n",
      "\"HistGradientBoostingClassifier_3_1\", 2.932320299965795 секунд\n",
      "\"HistGradientBoostingClassifier_7_1\", 7.252727900049649 секунд\n",
      "\"HistGradientBoostingClassifier_11_1\", 10.683208699978422 секунд\n",
      "\"HistGradientBoostingClassifier_3_5\", 2.951248100027442 секунд\n",
      "\"HistGradientBoostingClassifier_7_5\", 9.083637000003364 секунд\n",
      "\"HistGradientBoostingClassifier_11_5\", 12.033426399983 секунд\n",
      "\"RandomForestClassifier_g_3\", 0.5645648000063375 секунд\n",
      "\"RandomForestClassifier_g_7\", 0.5661854000063613 секунд\n",
      "\"RandomForestClassifier_g_11\", 0.6303286000038497 секунд\n",
      "\"RandomForestClassifier_e_3\", 0.5607343000010587 секунд\n",
      "\"RandomForestClassifier_e_7\", 0.4812355999602005 секунд\n",
      "\"RandomForestClassifier_e_11\", 0.5868655999656767 секунд\n",
      "\"RandomForestClassifier_ll_3\", 0.48399269999936223 секунд\n",
      "\"RandomForestClassifier_ll_7\", 0.4882279000012204 секунд\n",
      "\"RandomForestClassifier_ll_11\", 0.6480852999957278 секунд\n",
      "Суммарное время обучения ансамблей: 872.0997773999698 секунд\n"
     ]
    }
   ],
   "source": [
    "skl_ensembles_fit = dict()\n",
    "start = time.perf_counter()\n",
    "for ensemble in skl_ensembles:\n",
    "    time1 = time.perf_counter()\n",
    "    skl_ensembles_fit[ensemble] = skl_ensembles[ensemble].fit(X_train, y_train)\n",
    "    print(f'\"{ensemble}\", {time.perf_counter() - time1} секунд')\n",
    "print('Суммарное время обучения ансамблей:', time.perf_counter() - start, 'секунд')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad24691-35f6-4e61-aa4c-fbcad29d226b",
   "metadata": {},
   "source": [
    "Расчёт элементов матрицы ошибок и метрики LogLoss для каждой модели из \"skl_ensembles_fit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8de870d-6fbc-49e2-8a4b-20a6f54d46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_e = dict()\n",
    "fp_e = dict()\n",
    "fn_e = dict()\n",
    "tp_e = dict()\n",
    "logloss_e = dict()\n",
    "for ensemble in skl_ensembles_fit:\n",
    "    y_pred = skl_ensembles_fit[ensemble].predict(X_test)\n",
    "    (tn, fp, fn, tp) = confusion_matrix(y_true = y_test, y_pred = y_pred).ravel().tolist()\n",
    "    tn_e[ensemble], fp_e[ensemble], fn_e[ensemble], tp_e[ensemble] = tn, fp, fn, tp\n",
    "    logloss_e[ensemble] = log_loss(y_true = y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638cfb13-a35e-4b6d-ab80-43846e5d11eb",
   "metadata": {},
   "source": [
    "Расчёт метрик на тестовых данных и формирование общей таблицы с её сохранением, где индекс - модель, столбец - метрика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "479234ee-a0ac-41aa-9864-ad29da2b8fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_3</th>\n",
       "      <td>695.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.966620</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.935069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_7</th>\n",
       "      <td>699.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>1.567115</td>\n",
       "      <td>0.935691</td>\n",
       "      <td>0.920886</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>0.034530</td>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.948088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_11</th>\n",
       "      <td>706.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1.567115</td>\n",
       "      <td>0.956229</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.981919</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>0.926591</td>\n",
       "      <td>0.947376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_gnb</th>\n",
       "      <td>673.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2.681509</td>\n",
       "      <td>0.861027</td>\n",
       "      <td>0.901899</td>\n",
       "      <td>0.936022</td>\n",
       "      <td>0.044034</td>\n",
       "      <td>0.880989</td>\n",
       "      <td>0.912286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_dt_3</th>\n",
       "      <td>684.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>6.442585</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.525316</td>\n",
       "      <td>0.951321</td>\n",
       "      <td>0.179856</td>\n",
       "      <td>0.642166</td>\n",
       "      <td>0.742814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_dt_7</th>\n",
       "      <td>694.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>4.527222</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.667722</td>\n",
       "      <td>0.965229</td>\n",
       "      <td>0.131414</td>\n",
       "      <td>0.764493</td>\n",
       "      <td>0.832738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_dt_11</th>\n",
       "      <td>695.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.482479</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.966620</td>\n",
       "      <td>0.098573</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.877087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier_gnb</th>\n",
       "      <td>671.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>2.646684</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.933241</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.883436</td>\n",
       "      <td>0.913836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_g_3</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_g_7</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.586735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297165</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.134426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_g_11</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.367867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272267</td>\n",
       "      <td>0.258953</td>\n",
       "      <td>0.396136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_e_3</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_e_7</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.726034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299903</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.093178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_e_11</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.472342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274470</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.378784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_ll_3</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_ll_7</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.726034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299903</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.093178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier_ll_11</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.472342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274470</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.378784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_ll_fmse_3</th>\n",
       "      <td>700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.960107</td>\n",
       "      <td>0.929368</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>0.973574</td>\n",
       "      <td>0.086162</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.896574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_ll_fmse_7</th>\n",
       "      <td>702.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2.193962</td>\n",
       "      <td>0.940767</td>\n",
       "      <td>0.854430</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.925267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_ll_fmse_11</th>\n",
       "      <td>694.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>2.577034</td>\n",
       "      <td>0.914384</td>\n",
       "      <td>0.844937</td>\n",
       "      <td>0.965229</td>\n",
       "      <td>0.065949</td>\n",
       "      <td>0.878289</td>\n",
       "      <td>0.912454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_ll_se_3</th>\n",
       "      <td>700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.960107</td>\n",
       "      <td>0.929368</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>0.973574</td>\n",
       "      <td>0.086162</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.896574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_ll_se_7</th>\n",
       "      <td>702.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2.124312</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.899174</td>\n",
       "      <td>0.927825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_ll_se_11</th>\n",
       "      <td>699.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>2.368085</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>0.064257</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.919326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_e_fmse_3</th>\n",
       "      <td>697.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.412829</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.969402</td>\n",
       "      <td>0.098318</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.879327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_e_fmse_7</th>\n",
       "      <td>699.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2.298436</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.854430</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>0.061745</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_e_fmse_11</th>\n",
       "      <td>701.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>2.263611</td>\n",
       "      <td>0.937282</td>\n",
       "      <td>0.851266</td>\n",
       "      <td>0.974965</td>\n",
       "      <td>0.062834</td>\n",
       "      <td>0.892206</td>\n",
       "      <td>0.922858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_e_se_3</th>\n",
       "      <td>697.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.412829</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.969402</td>\n",
       "      <td>0.098318</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.879327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_e_se_7</th>\n",
       "      <td>699.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2.298436</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.854430</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>0.061745</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier_e_se_11</th>\n",
       "      <td>698.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>2.437735</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.844937</td>\n",
       "      <td>0.970793</td>\n",
       "      <td>0.065596</td>\n",
       "      <td>0.884106</td>\n",
       "      <td>0.916914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_3_0</th>\n",
       "      <td>663.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>2.577034</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.922114</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.889552</td>\n",
       "      <td>0.917445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_0</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.880538</td>\n",
       "      <td>0.892216</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.916923</td>\n",
       "      <td>0.938907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>692.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.532291</td>\n",
       "      <td>0.917178</td>\n",
       "      <td>0.946203</td>\n",
       "      <td>0.962448</td>\n",
       "      <td>0.023977</td>\n",
       "      <td>0.931464</td>\n",
       "      <td>0.949952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_3_1</th>\n",
       "      <td>664.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>2.542209</td>\n",
       "      <td>0.844193</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.923505</td>\n",
       "      <td>0.026393</td>\n",
       "      <td>0.890882</td>\n",
       "      <td>0.918504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_1</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.880538</td>\n",
       "      <td>0.892216</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.916923</td>\n",
       "      <td>0.938907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_1</th>\n",
       "      <td>689.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>1.810889</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.958275</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.940658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_3_5</th>\n",
       "      <td>658.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>2.751158</td>\n",
       "      <td>0.830084</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.915160</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>0.882963</td>\n",
       "      <td>0.912167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_5</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.028450</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.936509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_5</th>\n",
       "      <td>686.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2.054662</td>\n",
       "      <td>0.897833</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.036517</td>\n",
       "      <td>0.907668</td>\n",
       "      <td>0.932520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_g_3</th>\n",
       "      <td>647.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>4.004850</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.863924</td>\n",
       "      <td>0.899861</td>\n",
       "      <td>0.062319</td>\n",
       "      <td>0.826021</td>\n",
       "      <td>0.869756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_g_7</th>\n",
       "      <td>669.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.681509</td>\n",
       "      <td>0.852507</td>\n",
       "      <td>0.914557</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.882443</td>\n",
       "      <td>0.912922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_g_11</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>2.019838</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.910217</td>\n",
       "      <td>0.934100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_e_3</th>\n",
       "      <td>645.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4.109325</td>\n",
       "      <td>0.786127</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.897079</td>\n",
       "      <td>0.063861</td>\n",
       "      <td>0.821752</td>\n",
       "      <td>0.866407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_e_7</th>\n",
       "      <td>669.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2.646684</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.037410</td>\n",
       "      <td>0.884146</td>\n",
       "      <td>0.914145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_e_11</th>\n",
       "      <td>686.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2.159137</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.908228</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.902516</td>\n",
       "      <td>0.928849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_ll_3</th>\n",
       "      <td>645.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4.109325</td>\n",
       "      <td>0.786127</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.897079</td>\n",
       "      <td>0.063861</td>\n",
       "      <td>0.821752</td>\n",
       "      <td>0.866407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_ll_7</th>\n",
       "      <td>669.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2.646684</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.037410</td>\n",
       "      <td>0.884146</td>\n",
       "      <td>0.914145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_ll_11</th>\n",
       "      <td>686.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2.159137</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.908228</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.902516</td>\n",
       "      <td>0.928849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          TN    FP     FN     TP    LogLoss  \\\n",
       "AdaBoostClassifier_dt_3                695.0  24.0   32.0  284.0   1.950188   \n",
       "AdaBoostClassifier_dt_7                699.0  20.0   25.0  291.0   1.567115   \n",
       "AdaBoostClassifier_dt_11               706.0  13.0   32.0  284.0   1.567115   \n",
       "AdaBoostClassifier_gnb                 673.0  46.0   31.0  285.0   2.681509   \n",
       "BaggingClassifier_dt_3                 684.0  35.0  150.0  166.0   6.442585   \n",
       "BaggingClassifier_dt_7                 694.0  25.0  105.0  211.0   4.527222   \n",
       "BaggingClassifier_dt_11                695.0  24.0   76.0  240.0   3.482479   \n",
       "BaggingClassifier_gnb                  671.0  48.0   28.0  288.0   2.646684   \n",
       "ExtraTreesClassifier_g_3               719.0   0.0  316.0    0.0  11.004632   \n",
       "ExtraTreesClassifier_g_7               719.0   0.0  304.0   12.0  10.586735   \n",
       "ExtraTreesClassifier_g_11              719.0   0.0  269.0   47.0   9.367867   \n",
       "ExtraTreesClassifier_e_3               719.0   0.0  316.0    0.0  11.004632   \n",
       "ExtraTreesClassifier_e_7               719.0   0.0  308.0    8.0  10.726034   \n",
       "ExtraTreesClassifier_e_11              719.0   0.0  272.0   44.0   9.472342   \n",
       "ExtraTreesClassifier_ll_3              719.0   0.0  316.0    0.0  11.004632   \n",
       "ExtraTreesClassifier_ll_7              719.0   0.0  308.0    8.0  10.726034   \n",
       "ExtraTreesClassifier_ll_11             719.0   0.0  272.0   44.0   9.472342   \n",
       "GradientBoostingClassifier_ll_fmse_3   700.0  19.0   66.0  250.0   2.960107   \n",
       "GradientBoostingClassifier_ll_fmse_7   702.0  17.0   46.0  270.0   2.193962   \n",
       "GradientBoostingClassifier_ll_fmse_11  694.0  25.0   49.0  267.0   2.577034   \n",
       "GradientBoostingClassifier_ll_se_3     700.0  19.0   66.0  250.0   2.960107   \n",
       "GradientBoostingClassifier_ll_se_7     702.0  17.0   44.0  272.0   2.124312   \n",
       "GradientBoostingClassifier_ll_se_11    699.0  20.0   48.0  268.0   2.368085   \n",
       "GradientBoostingClassifier_e_fmse_3    697.0  22.0   76.0  240.0   3.412829   \n",
       "GradientBoostingClassifier_e_fmse_7    699.0  20.0   46.0  270.0   2.298436   \n",
       "GradientBoostingClassifier_e_fmse_11   701.0  18.0   47.0  269.0   2.263611   \n",
       "GradientBoostingClassifier_e_se_3      697.0  22.0   76.0  240.0   3.412829   \n",
       "GradientBoostingClassifier_e_se_7      699.0  20.0   46.0  270.0   2.298436   \n",
       "GradientBoostingClassifier_e_se_11     698.0  21.0   49.0  267.0   2.437735   \n",
       "HistGradientBoostingClassifier_3_0     663.0  56.0   18.0  298.0   2.577034   \n",
       "HistGradientBoostingClassifier_7_0     683.0  36.0   18.0  298.0   1.880538   \n",
       "HistGradientBoostingClassifier_11_0    692.0  27.0   17.0  299.0   1.532291   \n",
       "HistGradientBoostingClassifier_3_1     664.0  55.0   18.0  298.0   2.542209   \n",
       "HistGradientBoostingClassifier_7_1     683.0  36.0   18.0  298.0   1.880538   \n",
       "HistGradientBoostingClassifier_11_1    689.0  30.0   22.0  294.0   1.810889   \n",
       "HistGradientBoostingClassifier_3_5     658.0  61.0   18.0  298.0   2.751158   \n",
       "HistGradientBoostingClassifier_7_5     683.0  36.0   20.0  296.0   1.950188   \n",
       "HistGradientBoostingClassifier_11_5    686.0  33.0   26.0  290.0   2.054662   \n",
       "RandomForestClassifier_g_3             647.0  72.0   43.0  273.0   4.004850   \n",
       "RandomForestClassifier_g_7             669.0  50.0   27.0  289.0   2.681509   \n",
       "RandomForestClassifier_g_11            683.0  36.0   22.0  294.0   2.019838   \n",
       "RandomForestClassifier_e_3             645.0  74.0   44.0  272.0   4.109325   \n",
       "RandomForestClassifier_e_7             669.0  50.0   26.0  290.0   2.646684   \n",
       "RandomForestClassifier_e_11            686.0  33.0   29.0  287.0   2.159137   \n",
       "RandomForestClassifier_ll_3            645.0  74.0   44.0  272.0   4.109325   \n",
       "RandomForestClassifier_ll_7            669.0  50.0   26.0  290.0   2.646684   \n",
       "RandomForestClassifier_ll_11           686.0  33.0   29.0  287.0   2.159137   \n",
       "\n",
       "                                       Precision    Recall  Specificity  \\\n",
       "AdaBoostClassifier_dt_3                 0.922078  0.898734     0.966620   \n",
       "AdaBoostClassifier_dt_7                 0.935691  0.920886     0.972184   \n",
       "AdaBoostClassifier_dt_11                0.956229  0.898734     0.981919   \n",
       "AdaBoostClassifier_gnb                  0.861027  0.901899     0.936022   \n",
       "BaggingClassifier_dt_3                  0.825871  0.525316     0.951321   \n",
       "BaggingClassifier_dt_7                  0.894068  0.667722     0.965229   \n",
       "BaggingClassifier_dt_11                 0.909091  0.759494     0.966620   \n",
       "BaggingClassifier_gnb                   0.857143  0.911392     0.933241   \n",
       "ExtraTreesClassifier_g_3                0.000000  0.000000     1.000000   \n",
       "ExtraTreesClassifier_g_7                1.000000  0.037975     1.000000   \n",
       "ExtraTreesClassifier_g_11               1.000000  0.148734     1.000000   \n",
       "ExtraTreesClassifier_e_3                0.000000  0.000000     1.000000   \n",
       "ExtraTreesClassifier_e_7                1.000000  0.025316     1.000000   \n",
       "ExtraTreesClassifier_e_11               1.000000  0.139241     1.000000   \n",
       "ExtraTreesClassifier_ll_3               0.000000  0.000000     1.000000   \n",
       "ExtraTreesClassifier_ll_7               1.000000  0.025316     1.000000   \n",
       "ExtraTreesClassifier_ll_11              1.000000  0.139241     1.000000   \n",
       "GradientBoostingClassifier_ll_fmse_3    0.929368  0.791139     0.973574   \n",
       "GradientBoostingClassifier_ll_fmse_7    0.940767  0.854430     0.976356   \n",
       "GradientBoostingClassifier_ll_fmse_11   0.914384  0.844937     0.965229   \n",
       "GradientBoostingClassifier_ll_se_3      0.929368  0.791139     0.973574   \n",
       "GradientBoostingClassifier_ll_se_7      0.941176  0.860759     0.976356   \n",
       "GradientBoostingClassifier_ll_se_11     0.930556  0.848101     0.972184   \n",
       "GradientBoostingClassifier_e_fmse_3     0.916031  0.759494     0.969402   \n",
       "GradientBoostingClassifier_e_fmse_7     0.931034  0.854430     0.972184   \n",
       "GradientBoostingClassifier_e_fmse_11    0.937282  0.851266     0.974965   \n",
       "GradientBoostingClassifier_e_se_3       0.916031  0.759494     0.969402   \n",
       "GradientBoostingClassifier_e_se_7       0.931034  0.854430     0.972184   \n",
       "GradientBoostingClassifier_e_se_11      0.927083  0.844937     0.970793   \n",
       "HistGradientBoostingClassifier_3_0      0.841808  0.943038     0.922114   \n",
       "HistGradientBoostingClassifier_7_0      0.892216  0.943038     0.949930   \n",
       "HistGradientBoostingClassifier_11_0     0.917178  0.946203     0.962448   \n",
       "HistGradientBoostingClassifier_3_1      0.844193  0.943038     0.923505   \n",
       "HistGradientBoostingClassifier_7_1      0.892216  0.943038     0.949930   \n",
       "HistGradientBoostingClassifier_11_1     0.907407  0.930380     0.958275   \n",
       "HistGradientBoostingClassifier_3_5      0.830084  0.943038     0.915160   \n",
       "HistGradientBoostingClassifier_7_5      0.891566  0.936709     0.949930   \n",
       "HistGradientBoostingClassifier_11_5     0.897833  0.917722     0.954103   \n",
       "RandomForestClassifier_g_3              0.791304  0.863924     0.899861   \n",
       "RandomForestClassifier_g_7              0.852507  0.914557     0.930459   \n",
       "RandomForestClassifier_g_11             0.890909  0.930380     0.949930   \n",
       "RandomForestClassifier_e_3              0.786127  0.860759     0.897079   \n",
       "RandomForestClassifier_e_7              0.852941  0.917722     0.930459   \n",
       "RandomForestClassifier_e_11             0.896875  0.908228     0.954103   \n",
       "RandomForestClassifier_ll_3             0.786127  0.860759     0.897079   \n",
       "RandomForestClassifier_ll_7             0.852941  0.917722     0.930459   \n",
       "RandomForestClassifier_ll_11            0.896875  0.908228     0.954103   \n",
       "\n",
       "                                            NPV  F1-score  P4-score  \n",
       "AdaBoostClassifier_dt_3                0.044017  0.910256  0.935069  \n",
       "AdaBoostClassifier_dt_7                0.034530  0.928230  0.948088  \n",
       "AdaBoostClassifier_dt_11               0.043360  0.926591  0.947376  \n",
       "AdaBoostClassifier_gnb                 0.044034  0.880989  0.912286  \n",
       "BaggingClassifier_dt_3                 0.179856  0.642166  0.742814  \n",
       "BaggingClassifier_dt_7                 0.131414  0.764493  0.832738  \n",
       "BaggingClassifier_dt_11                0.098573  0.827586  0.877087  \n",
       "BaggingClassifier_gnb                  0.040057  0.883436  0.913836  \n",
       "ExtraTreesClassifier_g_3               0.305314  0.000000  0.000000  \n",
       "ExtraTreesClassifier_g_7               0.297165  0.073171  0.134426  \n",
       "ExtraTreesClassifier_g_11              0.272267  0.258953  0.396136  \n",
       "ExtraTreesClassifier_e_3               0.305314  0.000000  0.000000  \n",
       "ExtraTreesClassifier_e_7               0.299903  0.049383  0.093178  \n",
       "ExtraTreesClassifier_e_11              0.274470  0.244444  0.378784  \n",
       "ExtraTreesClassifier_ll_3              0.305314  0.000000  0.000000  \n",
       "ExtraTreesClassifier_ll_7              0.299903  0.049383  0.093178  \n",
       "ExtraTreesClassifier_ll_11             0.274470  0.244444  0.378784  \n",
       "GradientBoostingClassifier_ll_fmse_3   0.086162  0.854701  0.896574  \n",
       "GradientBoostingClassifier_ll_fmse_7   0.061497  0.895522  0.925267  \n",
       "GradientBoostingClassifier_ll_fmse_11  0.065949  0.878289  0.912454  \n",
       "GradientBoostingClassifier_ll_se_3     0.086162  0.854701  0.896574  \n",
       "GradientBoostingClassifier_ll_se_7     0.058981  0.899174  0.927825  \n",
       "GradientBoostingClassifier_ll_se_11    0.064257  0.887417  0.919326  \n",
       "GradientBoostingClassifier_e_fmse_3    0.098318  0.830450  0.879327  \n",
       "GradientBoostingClassifier_e_fmse_7    0.061745  0.891089  0.921900  \n",
       "GradientBoostingClassifier_e_fmse_11   0.062834  0.892206  0.922858  \n",
       "GradientBoostingClassifier_e_se_3      0.098318  0.830450  0.879327  \n",
       "GradientBoostingClassifier_e_se_7      0.061745  0.891089  0.921900  \n",
       "GradientBoostingClassifier_e_se_11     0.065596  0.884106  0.916914  \n",
       "HistGradientBoostingClassifier_3_0     0.026432  0.889552  0.917445  \n",
       "HistGradientBoostingClassifier_7_0     0.025678  0.916923  0.938907  \n",
       "HistGradientBoostingClassifier_11_0    0.023977  0.931464  0.949952  \n",
       "HistGradientBoostingClassifier_3_1     0.026393  0.890882  0.918504  \n",
       "HistGradientBoostingClassifier_7_1     0.025678  0.916923  0.938907  \n",
       "HistGradientBoostingClassifier_11_1    0.030942  0.918750  0.940658  \n",
       "HistGradientBoostingClassifier_3_5     0.026627  0.882963  0.912167  \n",
       "HistGradientBoostingClassifier_7_5     0.028450  0.913580  0.936509  \n",
       "HistGradientBoostingClassifier_11_5    0.036517  0.907668  0.932520  \n",
       "RandomForestClassifier_g_3             0.062319  0.826021  0.869756  \n",
       "RandomForestClassifier_g_7             0.038793  0.882443  0.912922  \n",
       "RandomForestClassifier_g_11            0.031206  0.910217  0.934100  \n",
       "RandomForestClassifier_e_3             0.063861  0.821752  0.866407  \n",
       "RandomForestClassifier_e_7             0.037410  0.884146  0.914145  \n",
       "RandomForestClassifier_e_11            0.040559  0.902516  0.928849  \n",
       "RandomForestClassifier_ll_3            0.063861  0.821752  0.866407  \n",
       "RandomForestClassifier_ll_7            0.037410  0.884146  0.914145  \n",
       "RandomForestClassifier_ll_11           0.040559  0.902516  0.928849  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_e = pd.DataFrame([tn_e, fp_e, fn_e, tp_e, logloss_e], index = ['TN', 'FP', 'FN', 'TP', 'LogLoss']).T\n",
    "results_e['Precision'] = Precision(tn = results_e['TN'], fp = results_e['FP'], fn = results_e['FN'], tp = results_e['TP'])\n",
    "results_e['Recall'] = Recall(tn = results_e['TN'], fp = results_e['FP'], fn = results_e['FN'], tp = results_e['TP'])\n",
    "results_e['Specificity'] = Specificity(tn = results_e['TN'], fp = results_e['FP'], fn = results_e['FN'], tp = results_e['TP'])\n",
    "results_e['NPV'] = NPV(tn = results_e['TN'], fp = results_e['FP'], fn = results_e['FN'], tp = results_e['TP'])\n",
    "results_e['F1-score'] = F1_score(tn = results_e['TN'], fp = results_e['FP'], fn = results_e['FN'], tp = results_e['TP'])\n",
    "results_e['P4-score'] = P4_score(tn = results_e['TN'], fp = results_e['FP'], fn = results_e['FN'], tp = results_e['TP'])\n",
    "results_e.to_csv('results/results_ensembles.csv', sep = ',', index_label = 'Ensembles')\n",
    "results_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83c6d4-7459-4df9-85fa-eaf3ca207fa0",
   "metadata": {},
   "source": [
    "Первые 10 лучших ансамблей по метрике LogLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f20924-b7af-4ed2-96b4-8d2f30492bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>1.532291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_7</th>\n",
       "      <td>1.567115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_11</th>\n",
       "      <td>1.567115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_1</th>\n",
       "      <td>1.810889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_1</th>\n",
       "      <td>1.880538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_0</th>\n",
       "      <td>1.880538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_3</th>\n",
       "      <td>1.950188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_5</th>\n",
       "      <td>1.950188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_g_11</th>\n",
       "      <td>2.019838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_5</th>\n",
       "      <td>2.054662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      LogLoss\n",
       "HistGradientBoostingClassifier_11_0  1.532291\n",
       "AdaBoostClassifier_dt_7              1.567115\n",
       "AdaBoostClassifier_dt_11             1.567115\n",
       "HistGradientBoostingClassifier_11_1  1.810889\n",
       "HistGradientBoostingClassifier_7_1   1.880538\n",
       "HistGradientBoostingClassifier_7_0   1.880538\n",
       "AdaBoostClassifier_dt_3              1.950188\n",
       "HistGradientBoostingClassifier_7_5   1.950188\n",
       "RandomForestClassifier_g_11          2.019838\n",
       "HistGradientBoostingClassifier_11_5  2.054662"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_e.sort_values(by = 'LogLoss')[:10][['LogLoss']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda938f2-0007-4d91-9bc2-0afd6024472a",
   "metadata": {},
   "source": [
    "Первые 10 лучших ансамблей по метрике F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eb30e0e-5477-4c04-99cd-3b320010269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>0.931464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_7</th>\n",
       "      <td>0.928230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_11</th>\n",
       "      <td>0.926591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_1</th>\n",
       "      <td>0.918750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_0</th>\n",
       "      <td>0.916923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_1</th>\n",
       "      <td>0.916923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_5</th>\n",
       "      <td>0.913580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_3</th>\n",
       "      <td>0.910256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_g_11</th>\n",
       "      <td>0.910217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_5</th>\n",
       "      <td>0.907668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     F1-score\n",
       "HistGradientBoostingClassifier_11_0  0.931464\n",
       "AdaBoostClassifier_dt_7              0.928230\n",
       "AdaBoostClassifier_dt_11             0.926591\n",
       "HistGradientBoostingClassifier_11_1  0.918750\n",
       "HistGradientBoostingClassifier_7_0   0.916923\n",
       "HistGradientBoostingClassifier_7_1   0.916923\n",
       "HistGradientBoostingClassifier_7_5   0.913580\n",
       "AdaBoostClassifier_dt_3              0.910256\n",
       "RandomForestClassifier_g_11          0.910217\n",
       "HistGradientBoostingClassifier_11_5  0.907668"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_e.sort_values(by = 'F1-score', ascending = False)[:10][['F1-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f8cb79-65ea-4c6c-b7dc-801af5b311a0",
   "metadata": {},
   "source": [
    "Первые 10 лучших ансамблей по метрике P4-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33c4843c-8bb3-407c-b6bb-baecc8c357ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>0.949952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_7</th>\n",
       "      <td>0.948088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_11</th>\n",
       "      <td>0.947376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_1</th>\n",
       "      <td>0.940658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_0</th>\n",
       "      <td>0.938907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_1</th>\n",
       "      <td>0.938907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_7_5</th>\n",
       "      <td>0.936509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier_dt_3</th>\n",
       "      <td>0.935069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier_g_11</th>\n",
       "      <td>0.934100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_5</th>\n",
       "      <td>0.932520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     P4-score\n",
       "HistGradientBoostingClassifier_11_0  0.949952\n",
       "AdaBoostClassifier_dt_7              0.948088\n",
       "AdaBoostClassifier_dt_11             0.947376\n",
       "HistGradientBoostingClassifier_11_1  0.940658\n",
       "HistGradientBoostingClassifier_7_0   0.938907\n",
       "HistGradientBoostingClassifier_7_1   0.938907\n",
       "HistGradientBoostingClassifier_7_5   0.936509\n",
       "AdaBoostClassifier_dt_3              0.935069\n",
       "RandomForestClassifier_g_11          0.934100\n",
       "HistGradientBoostingClassifier_11_5  0.932520"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_e.sort_values(by = 'P4-score', ascending = False)[:10][['P4-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ebc8be-406e-4196-9ea4-1b3b0a4ef5af",
   "metadata": {},
   "source": [
    "Как видно, лучшими ансамблями оказались ансамбли на основе гистограммного градиентного бустинга, а также на основе алгоритма AdaBoost. Результаты ансамблей оказались немного хуже результатов одиночных моделей, что может указывать скорее на неэффективность их обучения или подбора гиперпараметров, чем на объективное низкое качество ансамблей как метода.\n",
    "\n",
    "## Очищение памяти\n",
    "Перед дополнительными расчётами и обучениями новых моделей будет полезно освободить оперативную память от ненужных данных. Это особенно актуально на слабых ЭВМ с малым запасом ОЗУ. Для этого будет определён список топ объектов по объёму памяти (с помощью модуля \"pympler\") и принудительное удаление ненужных объектов за счёт вызова сборщика мусора (с помощью модуля \"gc\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3c86ca8-c566-45e9-b67f-7f673b6a96ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quit', 3086411376),\n",
       " ('exit', 3086410872),\n",
       " ('Out', 1745525168),\n",
       " ('skl_models', 951398376),\n",
       " ('skl_models_fit', 951398376),\n",
       " ('multicorr', 843827360),\n",
       " ('emails_rel', 253733512),\n",
       " ('emails', 253733336),\n",
       " ('X_train', 167369616),\n",
       " ('emails_rel_corr', 140179992)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = {name: val for name, val in globals().items() if not name.startswith('_')}\n",
    "size_list = list()\n",
    "for name, obj in variables.items():\n",
    "    try:\n",
    "        size = asizeof.asizeof(obj)\n",
    "        size_list.append((name, size))\n",
    "    except:\n",
    "        pass\n",
    "top_size_vars = sorted(size_list, key = lambda x: x[1], reverse = True)\n",
    "top_size_vars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc06229-64aa-4025-95b9-065911ee39b6",
   "metadata": {},
   "source": [
    "В случае нехватки ОЗУ можно удалить найденные лишние объекты. В данном случае это не необходимо, поэтому будут удалены только новые объекты и вызван сборщик мусора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ec0af0e-4d46-418b-905f-fa8fbe7020d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del variables, size_list, top_size_vars\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099b2f3-05e2-4c7d-b362-b5d36532be71",
   "metadata": {},
   "source": [
    "## Обучение ансамблей из CatBoost\n",
    "Дополнительно рассмотрим обучение ансамблей деревьев из библиотеки CatBoost. Во-первых, в данной библиотеке реализованы все 3 метода построения деревьев (как в XGBoost и LightGBM), а во-вторых, есть встроенное эффективное кодирование категориальных признаков, что может дать значительный буст в точности, однако в данном случае категориальных признаков нет, из-за чего использование ансамблей из CatBoost представляет интерес только с точки зрения различных построений деревьев.\n",
    "\n",
    "Сфромируем массивы разных значений гиперпараметров и словарь с различными вариантами ансамблей при всех перестановках данных гиперпараметров. Поскольку всех возможных перестановок гиперпараметров десятки тысяч - ограничим количество моделей 1000-ю штук, случайным образом выбирая гиперпараметры для последующего обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "495da7e0-2e32-49d4-85b7-bc0892448f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_funcs = {'Logloss': 'Logloss', 'CrossEntr': 'CrossEntropy'}\n",
    "leaf_estimation_methods = ('Newton', 'Gradient', 'Exact')\n",
    "auto_class_weights = {'None': None, 'Balanced': 'Balanced', 'SqrtBalanced': 'SqrtBalanced'}\n",
    "eval_metrics = {'Logloss': 'Logloss', 'CrossEntr': 'CrossEntropy', 'F1': 'F1', 'BalAcc': 'BalancedAccuracy',\n",
    "                'BalErrRate': 'BalancedErrorRate', 'MCC': 'MCC', 'AUC': 'AUC',\n",
    "                'PRAUC': 'PRAUC', 'LogLikeOfPred': 'LogLikelihoodOfPrediction'}\n",
    "boosting_types = ('Ordered', 'Plain')\n",
    "bootstrap_types = ('Bayesian', 'Bernoulli', 'MVS', 'No')\n",
    "max_depths = (2, 5, 7)\n",
    "grow_policies = {'ST': 'SymmetricTree', 'DW': 'Depthwise', 'LG': 'Lossguide'}\n",
    "score_functions = ('Cosine', 'L2')\n",
    "langevin_flag = {'lft': True, 'lff': False}\n",
    "\n",
    "counts = 1000\n",
    "CBC_ensembles = dict()\n",
    "for _ in range(counts):\n",
    "    lf = random.choice(tuple(loss_funcs.keys()))\n",
    "    lem = random.choice(leaf_estimation_methods)\n",
    "    acw = random.choice(tuple(auto_class_weights.keys()))\n",
    "    em = random.choice(tuple(eval_metrics.keys()))\n",
    "    bt = random.choice(boosting_types)\n",
    "    btr = random.choice(bootstrap_types)\n",
    "    md = random.choice(max_depths)\n",
    "    gp = random.choice(tuple(grow_policies.keys()))\n",
    "    sc = random.choice(score_functions)\n",
    "    lan = random.choice(tuple(langevin_flag.keys()))\n",
    "    CBC_ensembles[f'CB_{lf}_{lem}_{acw}_{em}_{bt}_{btr}_{md}_{gp}_{sc}_{lan}'] = CatBoostClassifier(\n",
    "        rsm = 0.5, loss_function = loss_funcs[lf], leaf_estimation_method = lem, random_seed = random_seed,\n",
    "        auto_class_weights = auto_class_weights[acw], eval_metric = eval_metrics[em], boosting_type = bt, bootstrap_type = btr,\n",
    "        max_depth = md, grow_policy = grow_policies[gp], score_function = sc, langevin = langevin_flag[lan], posterior_sampling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1d3f6-0748-4f72-a4df-82c652a5be51",
   "metadata": {},
   "source": [
    "Тренировка всех ансамблей из \"CBC_ensembles\" в отдельном словаре \"CBC_ensembles_fit\" с отслеживанием времени обучения. Поскольку некоторые варианты гиперпараметров конфликтуют друг с другом, из-за чего обучение будет прерываться с вызовом исключения, необходимо каждое обучение проводить в конструкции try/except с перехватом исключения. Обучение каждого ансамбля может занимать продолжительное времени, особенно при таком большом количестве признаков, всего необходимо обучить 1000 ансамблей из \"CBC_ensembles\", некоторые из которых будут пропущены из-за конфликта в гиперпараметрах. В любом случае следует ограничить длительность общего обучения разумным временем или достаточным количеством обученных ансамблей. Поэтому далее будут случайным образом из словаря \"CBC_ensembles\" выбираться ансамбли и обучаться (с отдельным запоминанием имён ансамблей в \"CBC_ensembles_check\"). При этом будут заданы следующие ограничения: общее время ограничено 1-м часом, количество рассмотренных для обучения ансамблей в \"CBC_ensembles_check\" ограничено общим числом ансамблей в \"CBC_ensembles\", количество обученных ансамблей в \"CBC_ensembles_fit\" ограничено заранее заданным числом ансамблей (20 штук). Все уникальные исключения будут записываться во множество \"exceptions_set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "330308f4-84e0-40ac-947a-f5540d079823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_2_LG_Cosine_lft\" 1/20: 20.05047660000855 секунд\n",
      "\"CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli_2_ST_L2_lft\" 2/20: 15.080202699988149 секунд\n",
      "\"CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft\" 3/20: 102.13015959999757 секунд\n",
      "\"CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW_Cosine_lft\" 4/20: 21.44541250000475 секунд\n",
      "\"CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernoulli_2_LG_L2_lft\" 5/20: 18.41922889999114 секунд\n",
      "\"CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft\" 6/20: 220.93988759996137 секунд\n",
      "\"CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No_2_ST_Cosine_lft\" 7/20: 16.073758399987128 секунд\n",
      "\"CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft\" 8/20: 150.69981499999994 секунд\n",
      "\"CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_2_ST_L2_lft\" 9/20: 32.181422399997246 секунд\n",
      "\"CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_ST_Cosine_lft\" 10/20: 11.987319300009403 секунд\n",
      "\"CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft\" 11/20: 14.18491820001509 секунд\n",
      "\"CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft\" 12/20: 47.72577270003967 секунд\n",
      "\"CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2_ST_L2_lft\" 13/20: 12.163880400010385 секунд\n",
      "\"CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft\" 14/20: 685.0641271999921 секунд\n",
      "\"CB_Logloss_Gradient_Balanced_Logloss_Ordered_MVS_7_ST_Cosine_lft\" 15/20: 727.4185328999883 секунд\n",
      "\"CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft\" 16/20: 115.6710957000032 секунд\n",
      "\"CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft\" 17/20: 594.4860184999998 секунд\n",
      "\"CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_DW_L2_lft\" 18/20: 21.800237699993886 секунд\n",
      "\"CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Bernoulli_5_ST_Cosine_lft\" 19/20: 77.12179699999979 секунд\n",
      "\"CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft\" 20/20: 112.99420899996767 секунд\n",
      "Суммарное время обучения CatBoost ансамблей: 3023.144458200026 секунд. Всего рассмотрено ансамблей: 138\n"
     ]
    }
   ],
   "source": [
    "CBC_ensembles_fit = dict()\n",
    "CBC_ensembles_check = set()\n",
    "exceptions_set = set()\n",
    "duration_sec = 3600\n",
    "count_max = 20\n",
    "start = time.perf_counter()\n",
    "while (time.perf_counter() - start < duration_sec and\n",
    "       len(CBC_ensembles_check) < len(CBC_ensembles.keys()) and\n",
    "       len(CBC_ensembles_fit.keys()) < count_max):\n",
    "    cb_ensemble = random.choice(tuple(CBC_ensembles.keys()))\n",
    "    if cb_ensemble not in CBC_ensembles_check:\n",
    "        try:\n",
    "            time1 = time.perf_counter()\n",
    "            CBC_ensembles_fit[cb_ensemble] = CBC_ensembles[cb_ensemble].fit(X_train, y_train, verbose = False)\n",
    "            print(f'\"{cb_ensemble}\" {len(CBC_ensembles_fit)}/{count_max}: {time.perf_counter() - time1} секунд')\n",
    "        except Exception as E:\n",
    "            exceptions_set.add(str(E))\n",
    "        finally:\n",
    "            CBC_ensembles_check.add(cb_ensemble)\n",
    "print('Суммарное время обучения CatBoost ансамблей:', time.perf_counter() - start, 'секунд. Всего рассмотрено ансамблей:', len(CBC_ensembles_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb4bac-2a80-443a-8de8-de2e360bb22d",
   "metadata": {},
   "source": [
    "Уникальные исключения, обработанные во время обучения ансамблей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45147203-340d-4474-9d7d-1238994853bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catboost/private/libs/options/catboost_options.cpp:345: Exact method is only available for Quantile, GroupQuantile, MultiQuantile, MAE, MAPE and LogCosh loss functions.',\n",
       " 'catboost/private/libs/options/catboost_options.cpp:617: class weights takes effect only with Logloss, MultiClass, MultiClassOneVsAll and user-defined loss functions',\n",
       " 'catboost/private/libs/options/catboost_options.cpp:745: Posterior Sampling requires Langevin boosting.',\n",
       " 'catboost/private/libs/options/catboost_options.cpp:758: Ordered boosting is not supported for nonsymmetric trees.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exceptions_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efac38b-d948-4097-9833-884585bc4a45",
   "metadata": {},
   "source": [
    "Расчёт элементов матрицы ошибок и метрики LogLoss для каждого обученного ансамбля из \"CBC_ensembles_fit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3a856f0-5ce6-4292-990f-43bb484a01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_cb = dict()\n",
    "fp_cb = dict()\n",
    "fn_cb = dict()\n",
    "tp_cb = dict()\n",
    "logloss_cb = dict()\n",
    "for ensemble in CBC_ensembles_fit:\n",
    "    (tn, fp, fn, tp) = get_confusion_matrix(CBC_ensembles_fit[ensemble], Pool(X_test, y_test)).ravel().astype(int).tolist()\n",
    "    tn_cb[ensemble], fp_cb[ensemble], fn_cb[ensemble], tp_cb[ensemble] = tn, fp, fn, tp\n",
    "    logloss_cb[ensemble] = log_loss(y_true = y_test, y_pred = CBC_ensembles_fit[ensemble].predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1009f9e-f09e-45cb-89ed-ac43eedfd6a7",
   "metadata": {},
   "source": [
    "Расчёт метрик на тестовых данных и формирование общей таблицы с её сохранением, где индекс - ансамбль, столбец - метрика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d53d2649-b93e-402f-adc9-72d09d51ccaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_2_LG_Cosine_lft</th>\n",
       "      <td>674.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2.019838</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.958861</td>\n",
       "      <td>0.937413</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>0.912651</td>\n",
       "      <td>0.935132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli_2_ST_L2_lft</th>\n",
       "      <td>697.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2.298436</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.969402</td>\n",
       "      <td>0.059379</td>\n",
       "      <td>0.891803</td>\n",
       "      <td>0.922225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>692.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1.288517</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.962448</td>\n",
       "      <td>0.014245</td>\n",
       "      <td>0.942989</td>\n",
       "      <td>0.958225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW_Cosine_lft</th>\n",
       "      <td>703.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>1.880538</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.879747</td>\n",
       "      <td>0.977747</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.911475</td>\n",
       "      <td>0.936536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernoulli_2_LG_L2_lft</th>\n",
       "      <td>678.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>0.880117</td>\n",
       "      <td>0.952532</td>\n",
       "      <td>0.942976</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.937066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>702.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1.497466</td>\n",
       "      <td>0.944625</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.930979</td>\n",
       "      <td>0.950225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No_2_ST_Cosine_lft</th>\n",
       "      <td>699.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>2.089487</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.929535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>688.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.532291</td>\n",
       "      <td>0.907186</td>\n",
       "      <td>0.958861</td>\n",
       "      <td>0.956885</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>0.932308</td>\n",
       "      <td>0.950307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_2_ST_L2_lft</th>\n",
       "      <td>687.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>1.810889</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.028289</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.940874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_ST_Cosine_lft</th>\n",
       "      <td>688.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.880538</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>0.927215</td>\n",
       "      <td>0.956885</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.915625</td>\n",
       "      <td>0.938353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft</th>\n",
       "      <td>701.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1.810889</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.892405</td>\n",
       "      <td>0.974965</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.939281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>702.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1.427816</td>\n",
       "      <td>0.944984</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.976356</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>0.952650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2_ST_L2_lft</th>\n",
       "      <td>700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>0.936242</td>\n",
       "      <td>0.882911</td>\n",
       "      <td>0.973574</td>\n",
       "      <td>0.050204</td>\n",
       "      <td>0.908795</td>\n",
       "      <td>0.934423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>705.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.288517</td>\n",
       "      <td>0.954397</td>\n",
       "      <td>0.927215</td>\n",
       "      <td>0.980529</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.940610</td>\n",
       "      <td>0.957221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_Logloss_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>1.706415</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.958861</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.018678</td>\n",
       "      <td>0.925191</td>\n",
       "      <td>0.944854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>706.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.462641</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.908228</td>\n",
       "      <td>0.981919</td>\n",
       "      <td>0.039456</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.951060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>703.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1.392991</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.977747</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.953770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_DW_L2_lft</th>\n",
       "      <td>701.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2.228786</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.854430</td>\n",
       "      <td>0.974965</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.924143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Bernoulli_5_ST_Cosine_lft</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1.636765</td>\n",
       "      <td>0.894428</td>\n",
       "      <td>0.965190</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.928463</td>\n",
       "      <td>0.947214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>704.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>1.497466</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.979138</td>\n",
       "      <td>0.038251</td>\n",
       "      <td>0.930533</td>\n",
       "      <td>0.950032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       TN    FP    FN     TP  \\\n",
       "CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_...  674.0  45.0  13.0  303.0   \n",
       "CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli...  697.0  22.0  44.0  272.0   \n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  692.0  27.0  10.0  306.0   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW...  703.0  16.0  38.0  278.0   \n",
       "CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernou...  678.0  41.0  15.0  301.0   \n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  702.0  17.0  26.0  290.0   \n",
       "CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No...  699.0  20.0  40.0  276.0   \n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  688.0  31.0  13.0  303.0   \n",
       "CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_...  687.0  32.0  20.0  296.0   \n",
       "CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_S...  688.0  31.0  23.0  293.0   \n",
       "CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft     701.0  18.0  34.0  282.0   \n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  702.0  17.0  24.0  292.0   \n",
       "CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2...  700.0  19.0  37.0  279.0   \n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  705.0  14.0  23.0  293.0   \n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  683.0  36.0  13.0  303.0   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  706.0  13.0  29.0  287.0   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  703.0  16.0  24.0  292.0   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  701.0  18.0  46.0  270.0   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  683.0  36.0  11.0  305.0   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  704.0  15.0  28.0  288.0   \n",
       "\n",
       "                                                     LogLoss  Precision  \\\n",
       "CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_...  2.019838   0.870690   \n",
       "CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli...  2.298436   0.925170   \n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  1.288517   0.918919   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW...  1.880538   0.945578   \n",
       "CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernou...  1.950188   0.880117   \n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  1.497466   0.944625   \n",
       "CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No...  2.089487   0.932432   \n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  1.532291   0.907186   \n",
       "CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_...  1.810889   0.902439   \n",
       "CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_S...  1.880538   0.904321   \n",
       "CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft     1.810889   0.940000   \n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  1.427816   0.944984   \n",
       "CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2...  1.950188   0.936242   \n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  1.288517   0.954397   \n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  1.706415   0.893805   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  1.462641   0.956667   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  1.392991   0.948052   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  2.228786   0.937500   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  1.636765   0.894428   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  1.497466   0.950495   \n",
       "\n",
       "                                                      Recall  Specificity  \\\n",
       "CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_...  0.958861     0.937413   \n",
       "CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli...  0.860759     0.969402   \n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.968354     0.962448   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW...  0.879747     0.977747   \n",
       "CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernou...  0.952532     0.942976   \n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.917722     0.976356   \n",
       "CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No...  0.873418     0.972184   \n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.958861     0.956885   \n",
       "CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_...  0.936709     0.955494   \n",
       "CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_S...  0.927215     0.956885   \n",
       "CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft     0.892405     0.974965   \n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.924051     0.976356   \n",
       "CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2...  0.882911     0.973574   \n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.927215     0.980529   \n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  0.958861     0.949930   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.908228     0.981919   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.924051     0.977747   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  0.854430     0.974965   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.965190     0.949930   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.911392     0.979138   \n",
       "\n",
       "                                                         NPV  F1-score  \\\n",
       "CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_...  0.018923  0.912651   \n",
       "CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli...  0.059379  0.891803   \n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.014245  0.942989   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW...  0.051282  0.911475   \n",
       "CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernou...  0.021645  0.914894   \n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.035714  0.930979   \n",
       "CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No...  0.054127  0.901961   \n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.018545  0.932308   \n",
       "CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_...  0.028289  0.919255   \n",
       "CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_S...  0.032349  0.915625   \n",
       "CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft     0.046259  0.915584   \n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.033058  0.934400   \n",
       "CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2...  0.050204  0.908795   \n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.031593  0.940610   \n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  0.018678  0.925191   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.039456  0.931818   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.033012  0.935897   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  0.061580  0.894040   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.015850  0.928463   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.038251  0.930533   \n",
       "\n",
       "                                                    P4-score  \n",
       "CB_Logloss_Newton_Balanced_AUC_Plain_Bernoulli_...  0.935132  \n",
       "CB_CrossEntr_Newton_None_BalAcc_Plain_Bernoulli...  0.922225  \n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.958225  \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_2_DW...  0.936536  \n",
       "CB_Logloss_Gradient_Balanced_PRAUC_Plain_Bernou...  0.937066  \n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.950225  \n",
       "CB_CrossEntr_Newton_None_LogLikeOfPred_Plain_No...  0.929535  \n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.950307  \n",
       "CB_Logloss_Newton_SqrtBalanced_MCC_Ordered_MVS_...  0.940874  \n",
       "CB_Logloss_Newton_SqrtBalanced_F1_Plain_MVS_2_S...  0.938353  \n",
       "CB_Logloss_Newton_None_F1_Plain_MVS_2_LG_L2_lft     0.939281  \n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.952650  \n",
       "CB_CrossEntr_Newton_None_BalErrRate_Plain_MVS_2...  0.934423  \n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.957221  \n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  0.944854  \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.951060  \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.953770  \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  0.924143  \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.947214  \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.950032  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cb = pd.DataFrame([tn_cb, fp_cb, fn_cb, tp_cb, logloss_cb], index = ['TN', 'FP', 'FN', 'TP', 'LogLoss']).T\n",
    "results_cb['Precision'] = Precision(tn = results_cb['TN'], fp = results_cb['FP'], fn = results_cb['FN'], tp = results_cb['TP'])\n",
    "results_cb['Recall'] = Recall(tn = results_cb['TN'], fp = results_cb['FP'], fn = results_cb['FN'], tp = results_cb['TP'])\n",
    "results_cb['Specificity'] = Specificity(tn = results_cb['TN'], fp = results_cb['FP'], fn = results_cb['FN'], tp = results_cb['TP'])\n",
    "results_cb['NPV'] = NPV(tn = results_cb['TN'], fp = results_cb['FP'], fn = results_cb['FN'], tp = results_cb['TP'])\n",
    "results_cb['F1-score'] = F1_score(tn = results_cb['TN'], fp = results_cb['FP'], fn = results_cb['FN'], tp = results_cb['TP'])\n",
    "results_cb['P4-score'] = P4_score(tn = results_cb['TN'], fp = results_cb['FP'], fn = results_cb['FN'], tp = results_cb['TP'])\n",
    "results_cb.to_csv('results/results_CB_ensembles.csv', sep = ',', index_label = 'CatBoost_ensembles')\n",
    "results_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa528eb-f62e-4aac-aedc-be90b58bc7ac",
   "metadata": {},
   "source": [
    "Первые 10 лучших CatBoost ансамблей по метрике LogLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1299c489-5634-4e79-bb5e-65bc2b3de7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>1.288517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>1.288517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>1.392991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>1.427816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>1.462641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>1.497466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>1.497466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>1.532291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Bernoulli_5_ST_Cosine_lft</th>\n",
       "      <td>1.636765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_Logloss_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>1.706415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     LogLoss\n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  1.288517\n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  1.288517\n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  1.392991\n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  1.427816\n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  1.462641\n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  1.497466\n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  1.497466\n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  1.532291\n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  1.636765\n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  1.706415"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cb.sort_values(by = 'LogLoss')[:10][['LogLoss']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4348958-e07b-43f9-8e21-377760b2faa9",
   "metadata": {},
   "source": [
    "Первые 10 лучших CatBoost ансамблей по метрике F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72f480b9-228e-4516-841d-8931541bdc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>0.942989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>0.940610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>0.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>0.932308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>0.930979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>0.930533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Bernoulli_5_ST_Cosine_lft</th>\n",
       "      <td>0.928463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_Logloss_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>0.925191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    F1-score\n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.942989\n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.940610\n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.935897\n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.934400\n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.932308\n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.931818\n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.930979\n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.930533\n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.928463\n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  0.925191"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cb.sort_values(by = 'F1-score', ascending = False)[:10][['F1-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e0990-10f2-432b-aff9-1d2c825b6ddb",
   "metadata": {},
   "source": [
    "Первые 10 лучших CatBoost ансамблей по метрике P4-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e9d89cf-17ef-4219-a32c-ed199378f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>0.958225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>0.957221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>0.953770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>0.952650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>0.951060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>0.950307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>0.950225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>0.950032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Bernoulli_5_ST_Cosine_lft</th>\n",
       "      <td>0.947214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_Logloss_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>0.944854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P4-score\n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.958225\n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.957221\n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.953770\n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.952650\n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.951060\n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.950307\n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.950225\n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.950032\n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.947214\n",
       "CB_Logloss_Gradient_Balanced_Logloss_Ordered_MV...  0.944854"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cb.sort_values(by = 'P4-score', ascending = False)[:10][['P4-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b391430-7c88-4913-b047-e616b41b267a",
   "metadata": {},
   "source": [
    "## Сравнение моделей и выбор лучшей\n",
    "Создание общей таблицы результатов всех обученных моделей и ансамблей с сохранением таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ffa5718-278b-4d43-954e-71ce38e93dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_lbfgs</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l1_liblinear</th>\n",
       "      <td>704.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.064363</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.132911</td>\n",
       "      <td>0.979138</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>0.225201</td>\n",
       "      <td>0.354250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_liblinear</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_newton-cg</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_l2_newton-ch</th>\n",
       "      <td>719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.004632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>706.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.462641</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.908228</td>\n",
       "      <td>0.981919</td>\n",
       "      <td>0.039456</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.951060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>703.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1.392991</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.977747</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.953770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_DW_L2_lft</th>\n",
       "      <td>701.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2.228786</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.854430</td>\n",
       "      <td>0.974965</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.924143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Bernoulli_5_ST_Cosine_lft</th>\n",
       "      <td>683.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>1.636765</td>\n",
       "      <td>0.894428</td>\n",
       "      <td>0.965190</td>\n",
       "      <td>0.949930</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.928463</td>\n",
       "      <td>0.947214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>704.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>1.497466</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.979138</td>\n",
       "      <td>0.038251</td>\n",
       "      <td>0.930533</td>\n",
       "      <td>0.950032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       TN    FP     FN     TP  \\\n",
       "LogisticRegression_l2_lbfgs                         719.0   0.0  316.0    0.0   \n",
       "LogisticRegression_l1_liblinear                     704.0  15.0  274.0   42.0   \n",
       "LogisticRegression_l2_liblinear                     719.0   0.0  316.0    0.0   \n",
       "LogisticRegression_l2_newton-cg                     719.0   0.0  316.0    0.0   \n",
       "LogisticRegression_l2_newton-ch                     719.0   0.0  316.0    0.0   \n",
       "...                                                   ...   ...    ...    ...   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  706.0  13.0   29.0  287.0   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  703.0  16.0   24.0  292.0   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  701.0  18.0   46.0  270.0   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  683.0  36.0   11.0  305.0   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  704.0  15.0   28.0  288.0   \n",
       "\n",
       "                                                      LogLoss  Precision  \\\n",
       "LogisticRegression_l2_lbfgs                         11.004632   0.000000   \n",
       "LogisticRegression_l1_liblinear                     10.064363   0.736842   \n",
       "LogisticRegression_l2_liblinear                     11.004632   0.000000   \n",
       "LogisticRegression_l2_newton-cg                     11.004632   0.000000   \n",
       "LogisticRegression_l2_newton-ch                     11.004632   0.000000   \n",
       "...                                                       ...        ...   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...   1.462641   0.956667   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...   1.392991   0.948052   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...   2.228786   0.937500   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...   1.636765   0.894428   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...   1.497466   0.950495   \n",
       "\n",
       "                                                      Recall  Specificity  \\\n",
       "LogisticRegression_l2_lbfgs                         0.000000     1.000000   \n",
       "LogisticRegression_l1_liblinear                     0.132911     0.979138   \n",
       "LogisticRegression_l2_liblinear                     0.000000     1.000000   \n",
       "LogisticRegression_l2_newton-cg                     0.000000     1.000000   \n",
       "LogisticRegression_l2_newton-ch                     0.000000     1.000000   \n",
       "...                                                      ...          ...   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.908228     0.981919   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.924051     0.977747   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  0.854430     0.974965   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.965190     0.949930   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.911392     0.979138   \n",
       "\n",
       "                                                         NPV  F1-score  \\\n",
       "LogisticRegression_l2_lbfgs                         0.305314  0.000000   \n",
       "LogisticRegression_l1_liblinear                     0.280164  0.225201   \n",
       "LogisticRegression_l2_liblinear                     0.305314  0.000000   \n",
       "LogisticRegression_l2_newton-cg                     0.305314  0.000000   \n",
       "LogisticRegression_l2_newton-ch                     0.305314  0.000000   \n",
       "...                                                      ...       ...   \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.039456  0.931818   \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.033012  0.935897   \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  0.061580  0.894040   \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.015850  0.928463   \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.038251  0.930533   \n",
       "\n",
       "                                                    P4-score  \n",
       "LogisticRegression_l2_lbfgs                         0.000000  \n",
       "LogisticRegression_l1_liblinear                     0.354250  \n",
       "LogisticRegression_l2_liblinear                     0.000000  \n",
       "LogisticRegression_l2_newton-cg                     0.000000  \n",
       "LogisticRegression_l2_newton-ch                     0.000000  \n",
       "...                                                      ...  \n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.951060  \n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.953770  \n",
       "CB_CrossEntr_Newton_None_MCC_Plain_Bernoulli_2_...  0.924143  \n",
       "CB_Logloss_Gradient_Balanced_CrossEntr_Plain_Be...  0.947214  \n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.950032  \n",
       "\n",
       "[134 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([results_m, results_e, results_cb])\n",
    "results.to_csv('results/all_results.csv', sep = ',', index_label = 'All_models')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5152083-14da-407d-98cb-ce52f191fe6f",
   "metadata": {},
   "source": [
    "Первые 10 лучших моделей по метрике LogLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b47450ed-19df-4c8a-b90a-4f8ae5a3c9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>1.288517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>1.288517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>1.392991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>1.427816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_lbfgs</th>\n",
       "      <td>1.427816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>1.462641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>1.497466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>1.497466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>1.532291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>1.532291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     LogLoss\n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  1.288517\n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  1.288517\n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  1.392991\n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  1.427816\n",
       "MLPClassifier_t_lbfgs                               1.427816\n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  1.462641\n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  1.497466\n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  1.497466\n",
       "HistGradientBoostingClassifier_11_0                 1.532291\n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  1.532291"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('LogLoss')[['LogLoss']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03066c53-1562-479a-a556-df98d763118f",
   "metadata": {},
   "source": [
    "Первые 10 лучших моделей по метрике F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "687452f2-10e0-462c-9ae7-7074d5077bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>0.942989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>0.940610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_lbfgs</th>\n",
       "      <td>0.934609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>0.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>0.932308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>0.931464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>0.930979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>0.930533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    F1-score\n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.942989\n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.940610\n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.935897\n",
       "MLPClassifier_t_lbfgs                               0.934609\n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.934400\n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.932308\n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.931818\n",
       "HistGradientBoostingClassifier_11_0                 0.931464\n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.930979\n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.930533"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('F1-score', ascending = False)[['F1-score']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38775cf-fb22-42e4-be9e-a754794dbe57",
   "metadata": {},
   "source": [
    "Первые 10 лучших моделей по метрике P4-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fecae8c-d593-4584-9286-6ea8bbba46a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P4-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft</th>\n",
       "      <td>0.958225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST_Cosine_lft</th>\n",
       "      <td>0.957221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_CrossEntr_Ordered_Bayesian_7_ST_L2_lft</th>\n",
       "      <td>0.953770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier_t_lbfgs</th>\n",
       "      <td>0.952739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2_lft</th>\n",
       "      <td>0.952650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5_LG_L2_lft</th>\n",
       "      <td>0.951060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_L2_lft</th>\n",
       "      <td>0.950307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2_lft</th>\n",
       "      <td>0.950225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW_L2_lft</th>\n",
       "      <td>0.950032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier_11_0</th>\n",
       "      <td>0.949952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P4-score\n",
       "CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_...  0.958225\n",
       "CB_CrossEntr_Gradient_None_MCC_Ordered_MVS_7_ST...  0.957221\n",
       "CB_Logloss_Gradient_None_CrossEntr_Ordered_Baye...  0.953770\n",
       "MLPClassifier_t_lbfgs                               0.952739\n",
       "CB_Logloss_Newton_None_BalAcc_Plain_MVS_5_ST_L2...  0.952650\n",
       "CB_Logloss_Newton_None_Logloss_Plain_Bayesian_5...  0.951060\n",
       "CB_Logloss_Gradient_Balanced_AUC_Plain_No_7_ST_...  0.950307\n",
       "CB_Logloss_Gradient_None_MCC_Ordered_No_5_ST_L2...  0.950225\n",
       "CB_Logloss_Newton_None_BalErrRate_Plain_No_5_DW...  0.950032\n",
       "HistGradientBoostingClassifier_11_0                 0.949952"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('P4-score', ascending = False)[['P4-score']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f0775-29c1-4d41-9461-d1a2e363ac63",
   "metadata": {},
   "source": [
    "Как видно из сравнения по всем рассчитываемым метрикам - CatBoost ансамбли лучше \"обычных\" ансамблей и одиночных моделей справляются с классификацией спама. Помимо CatBoost ансамблей, сравнимым по качеству классификатором оказалась одиночная модель многослойного персептрона (с одним скрытым слоем). Таким образом, будем считать, что лучшая обученная модель имеет следующее имя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bf679c2-48df-4c88-8455-45e60bb20b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"CB_Logloss_Newton_Balanced_CrossEntr_Plain_MVS_5_LG_L2_lft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca8d34-d48c-411f-84ca-4a3d597eb029",
   "metadata": {},
   "source": [
    "Параметры обучения модели имеют следующие значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fec84b01-a62c-4f71-b4ab-ae1ef6907e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rsm': 0.5,\n",
       " 'loss_function': 'Logloss',\n",
       " 'leaf_estimation_method': 'Newton',\n",
       " 'random_seed': 1,\n",
       " 'auto_class_weights': 'Balanced',\n",
       " 'eval_metric': 'CrossEntropy',\n",
       " 'boosting_type': 'Plain',\n",
       " 'bootstrap_type': 'MVS',\n",
       " 'max_depth': 5,\n",
       " 'grow_policy': 'Lossguide',\n",
       " 'score_function': 'L2',\n",
       " 'langevin': True,\n",
       " 'posterior_sampling': True}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = CBC_ensembles_fit[best_model].get_params()\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c21e57-17d9-4f82-8985-b61830c3ee4f",
   "metadata": {},
   "source": [
    "Сохраним параметры модели в двух форматах: \"cbm\" (CatBoost binary format) и повсеместно используемый \"json\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6945574d-6c2f-4f0b-8759-e9bbc4f00815",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBC_ensembles_fit[best_model].save_model('best_model_params/best_model.cbm', format = 'cbm')\n",
    "CBC_ensembles_fit[best_model].save_model('best_model_params/best_model.json', format = 'json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396d14e-4b88-43a8-9397-4d67db42ec90",
   "metadata": {},
   "source": [
    "## Оценка качества лучшей модели\n",
    "Для более подробной оценки качества лучшей модели будут использоваться площади под ROC и PR кривыми, а также статистическая оценка. Для статистической оценки качества обучения лучшей модели будет использована кроссвалидация типа \"ShuffleSplit\" (с созданием выборок для обучения и тестирования по методу Монте-Карло в пропорции train/test 80%/20%). Всего 10 выборок.\n",
    "\n",
    "### ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "672e9ff4-cba1-49ef-b17c-2df9559fa46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true = y_test, y_score = CBC_ensembles_fit[best_model].predict_proba(X_test)[:, 1])\n",
    "roc_auc = roc_auc_score(y_true = y_test, y_score = CBC_ensembles_fit[best_model].predict_proba(X_test)[:, 1])\n",
    "display = RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = roc_auc, name = 'best_model')\n",
    "display.plot()\n",
    "x_plot = [k / len(fpr) for k in range(len(fpr))]\n",
    "plt.plot(x_plot, x_plot, '--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8520c-6502-4912-bb29-66f2034d8774",
   "metadata": {},
   "source": [
    "### PR-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82a1bb25-327d-47f8-9d5e-7841ff3de120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prec, recall, thresholds = precision_recall_curve(y_true = y_test,\n",
    "                                                  y_score = CBC_ensembles_fit[best_model].predict_proba(X_test)[:, 1])\n",
    "pr_auc = average_precision_score(y_true = y_test, y_score = CBC_ensembles_fit[best_model].predict_proba(X_test)[:, 1])\n",
    "pr_display = PrecisionRecallDisplay(precision = prec, recall = recall, average_precision = pr_auc, name = 'best_model')\n",
    "pr_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526790d0-10a5-4892-8f5a-93dc7dd00f4f",
   "metadata": {},
   "source": [
    "### Кроссвалидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c21302e8-f615-48c8-85e0-109f9d257473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/10]\n",
      "\n",
      "bestTest = 0.1242230947\n",
      "bestIteration = 996\n",
      "\n",
      "Training on fold [1/10]\n",
      "\n",
      "bestTest = 0.1507126847\n",
      "bestIteration = 990\n",
      "\n",
      "Training on fold [2/10]\n",
      "\n",
      "bestTest = 0.125488131\n",
      "bestIteration = 998\n",
      "\n",
      "Training on fold [3/10]\n",
      "\n",
      "bestTest = 0.1196612498\n",
      "bestIteration = 997\n",
      "\n",
      "Training on fold [4/10]\n",
      "\n",
      "bestTest = 0.1223144855\n",
      "bestIteration = 999\n",
      "\n",
      "Training on fold [5/10]\n",
      "\n",
      "bestTest = 0.1432244847\n",
      "bestIteration = 992\n",
      "\n",
      "Training on fold [6/10]\n",
      "\n",
      "bestTest = 0.1313044048\n",
      "bestIteration = 995\n",
      "\n",
      "Training on fold [7/10]\n",
      "\n",
      "bestTest = 0.1341848648\n",
      "bestIteration = 999\n",
      "\n",
      "Training on fold [8/10]\n",
      "\n",
      "bestTest = 0.1289141259\n",
      "bestIteration = 998\n",
      "\n",
      "Training on fold [9/10]\n",
      "\n",
      "bestTest = 0.1365634684\n",
      "bestIteration = 995\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-CrossEntropy-mean</th>\n",
       "      <th>test-CrossEntropy-std</th>\n",
       "      <th>train-CrossEntropy-mean</th>\n",
       "      <th>train-CrossEntropy-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.676540</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.674357</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.676540</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.674357</td>\n",
       "      <td>0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.656236</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.656236</td>\n",
       "      <td>0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.639133</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.639133</td>\n",
       "      <td>0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.631860</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.623659</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.631860</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.623659</td>\n",
       "      <td>0.002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.619128</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.608734</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.619128</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.608734</td>\n",
       "      <td>0.002196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0.131782</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.131782</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0.131749</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.131749</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0.131747</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.131747</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>0.131734</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.131734</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.131734</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.131734</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.001097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-CrossEntropy-mean  test-CrossEntropy-std  \\\n",
       "0             0                0.676540               0.001043   \n",
       "1             1                0.660506               0.001156   \n",
       "2             2                0.645533               0.002280   \n",
       "3             3                0.631860               0.002908   \n",
       "4             4                0.619128               0.002973   \n",
       "..          ...                     ...                    ...   \n",
       "995         995                0.131782               0.009768   \n",
       "996         996                0.131749               0.009779   \n",
       "997         997                0.131747               0.009776   \n",
       "998         998                0.131734               0.009826   \n",
       "999         999                0.131734               0.009802   \n",
       "\n",
       "     train-CrossEntropy-mean  train-CrossEntropy-std  test-Logloss-mean  \\\n",
       "0                   0.674357                0.001046           0.676540   \n",
       "1                   0.656236                0.001484           0.660506   \n",
       "2                   0.639133                0.001699           0.645533   \n",
       "3                   0.623659                0.002385           0.631860   \n",
       "4                   0.608734                0.002196           0.619128   \n",
       "..                       ...                     ...                ...   \n",
       "995                 0.019808                0.001102           0.131782   \n",
       "996                 0.019783                0.001100           0.131749   \n",
       "997                 0.019764                0.001097           0.131747   \n",
       "998                 0.019738                0.001097           0.131734   \n",
       "999                 0.019709                0.001097           0.131734   \n",
       "\n",
       "     test-Logloss-std  train-Logloss-mean  train-Logloss-std  \n",
       "0            0.001043            0.674357           0.001046  \n",
       "1            0.001156            0.656236           0.001484  \n",
       "2            0.002280            0.639133           0.001699  \n",
       "3            0.002908            0.623659           0.002385  \n",
       "4            0.002973            0.608734           0.002196  \n",
       "..                ...                 ...                ...  \n",
       "995          0.009768            0.019808           0.001102  \n",
       "996          0.009779            0.019783           0.001100  \n",
       "997          0.009776            0.019764           0.001097  \n",
       "998          0.009826            0.019738           0.001097  \n",
       "999          0.009802            0.019709           0.001097  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dataset = Pool(data = emails_rel_corr.drop(columns = [target]), label = emails_rel_corr[target])\n",
    "scores = cv(cv_dataset, folds = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state = random_seed),\n",
    "            params = best_params, verbose = False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b85a2-184d-44c5-ae9a-a04494c87878",
   "metadata": {},
   "source": [
    "График сходимости метрики Logloss на обучении и тесте от количества итераций обучения с неопределённостью по стандартному отклонению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d7636ea-5440-414a-9cca-f4696990ed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores.iterations, scores['train-Logloss-mean'], label = 'train-Logloss-mean')\n",
    "plt.fill_between(scores.iterations,\n",
    "                 scores['train-Logloss-mean'] - scores['train-Logloss-std'],\n",
    "                 scores['train-Logloss-mean'] + scores['train-Logloss-std'])\n",
    "plt.plot(scores.iterations, scores['test-Logloss-mean'], label = 'test-Logloss-mean')\n",
    "plt.fill_between(scores.iterations,\n",
    "                 scores['test-Logloss-mean'] - scores['test-Logloss-std'],\n",
    "                 scores['test-Logloss-mean'] + scores['test-Logloss-std'])\n",
    "plt.grid()\n",
    "plt.legend(prop = {'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6a88b-5630-49ff-9560-afcc7db4d0eb",
   "metadata": {},
   "source": [
    "Сравнение метрики Logloss на обучении и тесте на последней итерации с неопределённостью по стандартному отклонению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d83790b2-1ec8-4aa0-a01d-c86e141632cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(scores.iterations.values[-1], scores['test-Logloss-mean'].values[-1], yerr = scores['test-Logloss-std'].values[-1],\n",
    "             fmt = '*', capsize = 50, ecolor = 'b', elinewidth = 1, markersize = 0, capthick = 2)\n",
    "plt.errorbar(scores.iterations.values[-1], scores['train-Logloss-mean'].values[-1], yerr = scores['train-Logloss-std'].values[-1],\n",
    "             fmt = '*', capsize = 50, ecolor = 'r', elinewidth = 1, markersize = 0, capthick = 2)\n",
    "plt.scatter(scores.iterations.values[-1], scores['test-Logloss-mean'].values[-1],\n",
    "            label = 'test-Logloss-mean', marker = '*', linewidths = 5, color = 'b')\n",
    "plt.scatter(scores.iterations.values[-1], scores['train-Logloss-mean'].values[-1],\n",
    "            label = 'train-Logloss-mean', marker = '*', linewidths = 5, color = 'r')\n",
    "plt.ylim(0, 0.2)\n",
    "plt.xticks([scores.iterations.values[-1]])\n",
    "plt.legend(prop = {'size': 15}, markerscale = 1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ccbc07-f18d-4303-9d59-c6f28bf9b961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
